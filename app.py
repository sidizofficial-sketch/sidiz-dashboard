import streamlit as st
from google.cloud import bigquery
import pandas as pd
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ Intelligence Dashboard", layout="wide")

# Gemini ì„¤ì • (Secretsì— gemini_api_keyê°€ ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•¨)
if "gemini_api_key" in st.secrets:
    genai.configure(api_key=st.secrets["gemini_api_key"])
    model = genai.GenerativeModel('gemini-1.5-flash')
    HAS_GEMINI = True
else:
    HAS_GEMINI = False

# 2. BigQuery í´ë¼ì´ì–¸íŠ¸
@st.cache_resource
def get_bq_client():
    try:
        info = json.loads(st.secrets["gcp_service_account"]["json_key"])
        return bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    except Exception as e:
        st.error(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

client = get_bq_client()

# 3. ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (ìœ ì… ì†ŒìŠ¤ ë¶„ì„ ì¶”ê°€)
def get_dashboard_data(start_c, end_c, start_p, end_p, time_unit):
    if client is None: return None, None, None
    
    if time_unit == "ì¼ë³„":
        group_sql = "CAST(date AS STRING)"
    elif time_unit == "ì£¼ë³„":
        group_sql = "CONCAT(CAST(DATE_TRUNC(date, WEEK) AS STRING), ' ~ ', CAST(LAST_DAY(date, WEEK) AS STRING))"
    else: 
        group_sql = "CONCAT(CAST(DATE_TRUNC(date, MONTH) AS STRING), ' ~ ', CAST(LAST_DAY(date, MONTH) AS STRING))"

    # KPI ì¿¼ë¦¬
    summary_query = f"""
    WITH raw_data AS (
      SELECT 
        PARSE_DATE('%Y%m%d', event_date) as date,
        user_pseudo_id,
        (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as session_id,
        (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as session_num,
        event_name,
        ecommerce.purchase_revenue
      FROM `sidiz-458301.analytics_487246344.events_*`
      WHERE _TABLE_SUFFIX BETWEEN '{min(start_c, start_p).strftime('%Y%m%d')}' AND '{max(end_c, end_p).strftime('%Y%m%d')}'
    )
    SELECT 
        CASE 
            WHEN date BETWEEN '{start_c}' AND '{end_c}' THEN 'Current' 
            WHEN date BETWEEN '{start_p}' AND '{end_p}' THEN 'Previous' 
        END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN session_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(session_id AS STRING))) as sessions,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(purchase_revenue) as revenue
    FROM raw_data WHERE session_id IS NOT NULL GROUP BY 1 HAVING type IS NOT NULL
    """

    # ì‹œê³„ì—´ ì¿¼ë¦¬
    ts_query = f"""
    SELECT {group_sql} as period_label, SUM(ecommerce.purchase_revenue) as revenue,
    COUNTIF(event_name = 'purchase') as orders,
    COUNT(DISTINCT CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING))) as sessions
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{start_c.strftime('%Y%m%d')}' AND '{end_c.strftime('%Y%m%d')}'
    GROUP BY 1 ORDER BY 1
    """

    # AIë¥¼ ìœ„í•œ ë§¤ì²´ ë¶„ì„ ì¿¼ë¦¬ ì¶”ê°€
    source_query = f"""
    SELECT traffic_source.source, COUNTIF(event_name = 'purchase') as orders, SUM(ecommerce.purchase_revenue) as revenue
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{start_c.strftime('%Y%m%d')}' AND '{end_c.strftime('%Y%m%d')}'
    GROUP BY 1 ORDER BY revenue DESC LIMIT 5
    """
    
    try:
        summary_df = client.query(summary_query).to_dataframe()
        ts_df = client.query(ts_query).to_dataframe()
        source_df = client.query(source_query).to_dataframe()
        return summary_df, ts_df, source_df
    except Exception as e:
        st.error(f"âš ï¸ ë°ì´í„° ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None, None

# 4. ë©”ì¸ UI
st.title("ğŸª‘ SIDIZ AI Intelligence Dashboard")

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    curr_date = st.date_input("ë¶„ì„ ê¸°ê°„", [datetime.now() - timedelta(days=8), datetime.now() - timedelta(days=1)])
    comp_date = st.date_input("ë¹„êµ ê¸°ê°„", [datetime.now() - timedelta(days=16), datetime.now() - timedelta(days=9)])
    time_unit = st.selectbox("ì¶”ì´ ë¶„ì„ ë‹¨ìœ„", ["ì¼ë³„", "ì£¼ë³„", "ì›”ë³„"])

if len(curr_date) == 2 and len(comp_date) == 2:
    summary_df, ts_df, source_df = get_dashboard_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1], time_unit)
    
    if summary_df is not None and not summary_df.empty:
        curr = summary_df[summary_df['type'] == 'Current'].iloc[0]
        prev = summary_df[summary_df['type'] == 'Previous'].iloc[0] if 'Previous' in summary_df['type'].values else curr

        # [ì„¹ì…˜ 1: í•µì‹¬ ì„±ê³¼ ìš”ì•½]
        def calc_delta(c, p): return f"{((c - p) / p * 100):+.1f}%" if p > 0 else "0%"
        st.subheader("ğŸ¯ í•µì‹¬ ì„±ê³¼ ìš”ì•½")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("í™œì„± ì‚¬ìš©ì", f"{int(curr['users']):,}", calc_delta(curr['users'], prev['users']))
        c2.metric("ì‹ ê·œ ë°©ë¬¸ìœ¨", f"{(curr['new_users']/curr['users']*100 if curr['users']>0 else 0):.1f}%")
        c3.metric("ì´ ë§¤ì¶œì•¡", f"â‚©{int(curr['revenue'] or 0):,}", calc_delta(curr['revenue'], prev['revenue']))
        c4.metric("êµ¬ë§¤ì „í™˜ìœ¨(CVR)", f"{(curr['orders']/curr['sessions']*100 if curr['sessions']>0 else 0):.2f}%")

        # [ì„¹ì…˜ 2: ì¶”ì´ ë¶„ì„]
        st.markdown("---")
        fig = go.Figure()
        fig.add_trace(go.Bar(x=ts_df['period_label'], y=ts_df['revenue'], name='ë§¤ì¶œì•¡', marker_color='#2ca02c'))
        fig.add_trace(go.Scatter(x=ts_df['period_label'], y=ts_df['sessions'], name='ì„¸ì…˜', yaxis='y2', line=dict(color='#1f77b4')))
        fig.update_layout(yaxis2=dict(overlaying='y', side='right'), template="plotly_white", hovermode="x unified")
        st.plotly_chart(fig, use_container_width=True)

        # [ì„¹ì…˜ 3: ğŸ¤– AI ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ìš”ì•½]
        st.markdown("---")
        st.subheader("ğŸ¤– ì´ ê¸°ê°„ì˜ AI ë¶„ì„ ë¦¬í¬íŠ¸")
        
        if HAS_GEMINI:
            with st.spinner("AIê°€ ë¹…ì¿¼ë¦¬ ë°ì´í„°ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # AIì—ê²Œ ì¤„ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                context = f"""
                ë¶„ì„ ë°ì´í„° ìš”ì•½:
                - ë§¤ì¶œ: {int(curr['revenue']):,}ì› (ì „ê¸°ëŒ€ë¹„ {calc_delta(curr['revenue'], prev['revenue'])})
                - ì£¼ë¬¸ê±´ìˆ˜: {int(curr['orders'])}ê±´
                - ì „í™˜ìœ¨: {(curr['orders']/curr['sessions']*100):.2f}%
                - ìƒìœ„ ìœ ì… ì±„ë„: {', '.join(source_df['source'].tolist())}
                """
                
                prompt = f"""
                ë‹¹ì‹ ì€ ì‹œë””ì¦ˆì˜ ì‹œë‹ˆì–´ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
                ì•„ë˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì„ 3ì¤„ë¡œ ìš”ì•½í•˜ê³ , 
                ë§¤ì¶œì„ ë†’ì´ê¸° ìœ„í•œ ê°€ì¥ ì‹œê¸‰í•œ ì „ëµ 1ê°€ì§€ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
                ë°ì´í„°: {context}
                """
                try:
                    ai_res = model.generate_content(prompt).text
                    st.info(ai_res)
                except:
                    st.warning("AI ë¶„ì„ ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
