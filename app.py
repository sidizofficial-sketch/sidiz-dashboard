import streamlit as st
import google.generativeai as genai
from google.cloud import bigquery
import pandas as pd
import json
import datetime
import time  # ì‹œê°„ ì§€ì—°ì„ ìœ„í•´ ì¶”ê°€

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ AI Intelligence", page_icon="ğŸª‘", layout="wide")

# 2. ë³´ì•ˆ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„
try:
    # Secrets ì½ê¸°
    info = json.loads(st.secrets["gcp_service_account"]["json_key"])
    client = bigquery.Client.from_service_account_info(info)
    
    # Gemini API ì„¤ì •
    if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        
        # [ìˆ˜ì •] ê°€ì¥ ì•ˆì •ì ì¸ 1.5 Flash ëª¨ë¸ë¡œ ëª…í™•íˆ ì§€ì •
        model = genai.GenerativeModel('gemini-1.5-flash') 
        st.sidebar.success("âœ… ì‹œë””ì¦ˆ ë¶„ì„ ì—”ì§„ ì—°ê²° ì™„ë£Œ", icon="ğŸš€")
    else:
        st.sidebar.error("âŒ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", icon="ğŸš¨")
        st.stop()

    # ë‚ ì§œ ìë™ ê³„ì‚°
    today = datetime.date.today().strftime('%Y%m%d')

    # 3. ë°ì´í„° ë¶„ì„ ì§€ì¹¨
    INSTRUCTION = f"""
    ë‹¹ì‹ ì€ ì‹œë””ì¦ˆ(SIDIZ)ì˜ ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    - í”„ë¡œì íŠ¸ ID: `{info['project_id']}`
    - ë°ì´í„°ì…‹: `analytics_324424314`
    - í…Œì´ë¸”: `events_*`
    - ì˜¤ëŠ˜ ë‚ ì§œ: {today}
    
    [ê·œì¹™] ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë¹…ì¿¼ë¦¬ SQLì„ ì‘ì„±í•˜ê³  ê²°ê³¼ë¥¼ í•œê¸€ë¡œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.
    """

except Exception as e:
    st.error(f"ì´ˆê¸° ì„¤ì • ì˜¤ë¥˜: {e}", icon="ğŸ”¥")
    st.stop()

# 4. UI êµ¬ì„±
st.title("ğŸª‘ SIDIZ Data Intelligence Portal")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë¡œê·¸ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë°ì´í„°ì—ê²Œ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # [ê°•í™”] ì§€ì¹¨ê³¼ ì§ˆë¬¸ ê²°í•©
                full_query = f"{INSTRUCTION}\n\nì‚¬ìš©ì ì§ˆë¬¸: {prompt}"
                
                # API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
                response = model.generate_content(full_query)
                
                if response:
                    answer = response.text
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                
            except Exception as e:
                if "429" in str(e):
                    # 429 ì—ëŸ¬ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ë” ì¹œì ˆí•œ ê°€ì´ë“œ ì œê³µ
                    st.warning("âš ï¸ í˜„ì¬ êµ¬ê¸€ ì„œë²„ì˜ ë¬´ë£Œ í• ë‹¹ëŸ‰ì´ ê½‰ ì°¼ìŠµë‹ˆë‹¤.", icon="â³")
                    st.info("ğŸ’¡ **í•´ê²° ë°©ë²•:** 1ë¶„ ë’¤ì— ë‹¤ì‹œ ì§ˆë¬¸í•˜ê±°ë‚˜, AI Studioì—ì„œ 'ê²°ì œ(Billing)'ë¥¼ ë“±ë¡í•˜ë©´ ì¦‰ì‹œ í•´ê²°ë©ë‹ˆë‹¤.")
                else:
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", icon="ğŸš¨")
