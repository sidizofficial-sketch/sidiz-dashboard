import streamlit as st
from google.cloud import bigquery
import pandas as pd
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ Intelligence Dashboard", layout="wide")

if "gemini" in st.secrets and "gemini_api_key" in st.secrets["gemini"]:
    genai.configure(api_key=st.secrets["gemini"]["gemini_api_key"])
    model = genai.GenerativeModel('gemini-1.5-flash')
    HAS_GEMINI = True
else:
    HAS_GEMINI = False

@st.cache_resource
def get_bq_client():
    try:
        info = json.loads(st.secrets["gcp_service_account"]["json_key"])
        return bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    except Exception as e:
        st.error(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

client = get_bq_client()

# -------------------------------------------------
# 2. ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (ëŒ€ëŸ‰ êµ¬ë§¤ í¬í•¨)
# -------------------------------------------------
def get_dashboard_data(start_c, end_c, start_p, end_p, time_unit):
    if client is None: return None, None, None
    
    s_c, e_c = start_c.strftime('%Y%m%d'), end_c.strftime('%Y%m%d')
    s_p, e_p = start_p.strftime('%Y%m%d'), end_p.strftime('%Y%m%d')

    if time_unit == "ì¼ë³„": group_sql = "PARSE_DATE('%Y%m%d', event_date)"
    elif time_unit == "ì£¼ë³„": group_sql = "DATE_TRUNC(PARSE_DATE('%Y%m%d', event_date), WEEK)"
    else: group_sql = "DATE_TRUNC(PARSE_DATE('%Y%m%d', event_date), MONTH)"

    query = f"""
    WITH base AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id, event_name, ecommerce.purchase_revenue,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min(s_c, s_p)}' AND '{max(e_c, e_p)}'
    )
    SELECT 
        CASE WHEN date BETWEEN '{start_c}' AND '{end_c}' THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(sid AS STRING))) as sessions,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue
    FROM base GROUP BY 1 HAVING type IS NOT NULL
    """

    ts_query = f"""
    SELECT 
        CAST({group_sql} AS STRING) as period_label, 
        SUM(IFNULL(ecommerce.purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND ecommerce.purchase_revenue >= 1500000) as bulk_orders
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
    GROUP BY 1 ORDER BY 1
    """

    source_query = f"""
    SELECT traffic_source.source, SUM(IFNULL(ecommerce.purchase_revenue, 0)) as revenue
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
    GROUP BY 1 ORDER BY revenue DESC LIMIT 5
    """

    try:
        return client.query(query).to_dataframe(), client.query(ts_query).to_dataframe(), client.query(source_query).to_dataframe()
    except Exception as e:
        st.error(f"âš ï¸ ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None, None

# -------------------------------------------------
# 3. AI ì¸ì‚¬ì´íŠ¸ í•¨ìˆ˜ (ëŒ€ëŸ‰ êµ¬ë§¤ ë¡œì§ ê°•í™”)
# -------------------------------------------------
def generate_deep_report(curr, prev, source_df):
    if not HAS_GEMINI: return "ğŸ¤– AI API ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."

    # ì£¼ìš” ì§€í‘œ ê³„ì‚°
    rev_delta = ((curr['revenue'] - prev['revenue']) / prev['revenue'] * 100) if prev['revenue'] > 0 else 0
    c_cr = (curr['orders']/curr['sessions']*100) if curr['sessions'] > 0 else 0
    
    # ëŒ€ëŸ‰ êµ¬ë§¤ ì§€í‘œ
    c_bulk_share = (curr['bulk_revenue'] / curr['revenue'] * 100) if curr['revenue'] > 0 else 0
    p_bulk_share = (prev['bulk_revenue'] / prev['revenue'] * 100) if prev['revenue'] > 0 else 0
    bulk_delta = curr['bulk_orders'] - prev['bulk_orders']
    
    top_channels = source_df['source'].tolist()[:3] if not source_df.empty else ["N/A"]

    prompt = f"""
    ì‹œë””ì¦ˆ ë°ì´í„° ì „ëµê°€ë¡œì„œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. 
    íŠ¹íˆ 'ëŒ€ëŸ‰ êµ¬ë§¤(150ë§Œì› ì´ìƒ)' ë°ì´í„°ê°€ ì´ë²ˆ ì„±ê³¼ì— ë¯¸ì¹œ ì˜í–¥ì„ ë¶„ì„ì— ë°˜ë“œì‹œ í¬í•¨í•˜ë˜, ë³€í™”ê°€ ë‘ë“œëŸ¬ì§ˆ ë•Œë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ë‹¤ë£¨ì„¸ìš”.

    [í•µì‹¬ ë°ì´í„°]
    - ì „ì²´ ë§¤ì¶œ: {int(curr['revenue']):,}ì› ({rev_delta:+.1f}%)
    - ì „ì²´ ì£¼ë¬¸: {curr['orders']}ê±´ / ì „í™˜ìœ¨ {c_cr:.2f}%
    - ëŒ€ëŸ‰ êµ¬ë§¤: {curr['bulk_orders']}ê±´ (ë§¤ì¶œë¹„ì¤‘ {c_bulk_share:.1f}%, ì „ê¸°ëŒ€ë¹„ {bulk_delta:+}ê±´)
    - ì£¼ìš” ì±„ë„: {top_channels}

    [ì‘ì„± êµ¬ì¡°]
    1.ğŸ¯ í•œ ì¤„ ìš”ì•½: ë§¤ì¶œ ì„±íŒ¨ì˜ 'ì§„ì§œ ì›ì¸' (ëŒ€ëŸ‰êµ¬ë§¤ ì˜í–¥ë ¥ ì—¬ë¶€ í¬í•¨)
    2.ğŸ” í˜„ìƒ ë¶„ì„ (What): ëŒ€ëŸ‰êµ¬ë§¤ì™€ ì¼ë°˜êµ¬ë§¤ ì¤‘ ë¬´ì—‡ì´ ì§€í‘œë¥¼ ê²¬ì¸í–ˆëŠ”ì§€ ë¹„êµ.
    3.ğŸ’¡ ì¸ê³¼ ì¶”ë¡  (Why): ì±„ë„ ìœ ì…ê³¼ ëŒ€ëŸ‰ êµ¬ë§¤ ë°œìƒ ì‚¬ì´ì˜ ìƒê´€ê´€ê³„ ì¶”ì¸¡.
    4.ğŸš€ Action Plan: í˜„ì¬ ëŒ€ëŸ‰êµ¬ë§¤ ë¹„ì¤‘ì— ë”°ë¥¸ B2B í˜¹ì€ í”„ë¡œëª¨ì…˜ ì „ëµ ì œì•ˆ.
    """
    try:
        return model.generate_content(prompt).text
    except: return "ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨"

# -------------------------------------------------
# 4. ë©”ì¸ UI ë° ì¶œë ¥ (ìˆ˜ì • ë²„ì „)
# -------------------------------------------------
st.title("ğŸª‘ SIDIZ Intelligence Dashboard")

today = datetime.now()
with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    curr_date = st.date_input("ë¶„ì„ ê¸°ê°„", [today - timedelta(days=7), today - timedelta(days=1)])
    comp_date = st.date_input("ë¹„êµ ê¸°ê°„", [today - timedelta(days=14), today - timedelta(days=8)])
    time_unit = st.selectbox("ì¶”ì´ ë¶„ì„ ë‹¨ìœ„", ["ì¼ë³„", "ì£¼ë³„", "ì›”ë³„"])

if len(curr_date) == 2 and len(comp_date) == 2:
    summary_df, ts_df, source_df = get_dashboard_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1], time_unit)
    
    if summary_df is not None and not summary_df.empty:
        curr = summary_df[summary_df['type'] == 'Current'].iloc[0]
        prev = summary_df[summary_df['type'] == 'Previous'].iloc[0] if 'Previous' in summary_df['type'].values else curr

        # [8ëŒ€ ì§€í‘œ ì¶œë ¥]
        def get_delta(c, p):
            if p == 0: return "0%"
            return f"{((c - p) / p * 100):+.1f}%"

        st.subheader("ğŸ¯ í•µì‹¬ ì„±ê³¼ ìš”ì•½")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("í™œì„± ì‚¬ìš©ì", f"{int(curr['users']):,}", get_delta(curr['users'], prev['users']))
        c1.metric("ì„¸ì…˜ ìˆ˜", f"{int(curr['sessions']):,}", get_delta(curr['sessions'], prev['sessions']))
        
        c2.metric("ì‹ ê·œ ì‚¬ìš©ì", f"{int(curr['new_users']):,}", get_delta(curr['new_users'], prev['new_users']))
        c2.metric("ì£¼ë¬¸ ìˆ˜", f"{int(curr['orders']):,}", get_delta(curr['orders'], prev['orders']))
        
        c_nv = (curr['new_users']/curr['users']*100) if curr['users'] > 0 else 0
        p_nv = (prev['new_users']/prev['users']*100) if prev['users'] > 0 else 0
        c3.metric("ì‹ ê·œ ë°©ë¬¸ìœ¨", f"{c_nv:.1f}%", f"{c_nv-p_nv:+.1f}%p")
        c3.metric("êµ¬ë§¤ì „í™˜ìœ¨", f"{(curr['orders']/curr['sessions']*100):.2f}%", f"{(curr['orders']/curr['sessions']*100 - prev['orders']/prev['sessions']*100):+.2f}%p")
        
        c4.metric("ì´ ë§¤ì¶œì•¡", f"â‚©{int(curr['revenue']):,}", get_delta(curr['revenue'], prev['revenue']))
        c_aov = (curr['revenue']/curr['orders']) if curr['orders'] > 0 else 0
        p_aov = (prev['revenue']/prev['orders']) if prev['orders'] > 0 else 0
        c4.metric("í‰ê·  ê°ë‹¨ê°€(AOV)", f"â‚©{int(c_aov):,}", get_delta(c_aov, p_aov))

        # [ëŒ€ëŸ‰ êµ¬ë§¤ ì„±ê³¼ ì„¹ì…˜]
        st.markdown("---")
        st.subheader("ğŸ“¦ ëŒ€ëŸ‰ êµ¬ë§¤ ì„¸ê·¸ë¨¼íŠ¸ (150ë§Œ ì›â†‘)")
        b1, b2, b3 = st.columns(3)
        b1.metric("ëŒ€ëŸ‰ ì£¼ë¬¸ ê±´ìˆ˜", f"{int(curr['bulk_orders'])}ê±´", f"{int(curr['bulk_orders'] - prev['bulk_orders']):+}ê±´")
        b2.metric("ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ", f"â‚©{int(curr['bulk_revenue']):,}", get_delta(curr['bulk_revenue'], prev['bulk_revenue']))
        b3.metric("ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ ë¹„ì¤‘", f"{(curr['bulk_revenue']/curr['revenue']*100 if curr['revenue']>0 else 0):.1f}%")

        # [ì°¨íŠ¸ ì„¹ì…˜]
        st.markdown("---")
        st.subheader(f"ğŸ“Š {time_unit} ë§¤ì¶œ ì¶”ì´")
        fig = go.Figure()
        fig.add_bar(x=ts_df['period_label'], y=ts_df['revenue'], name="ì „ì²´ ë§¤ì¶œ", marker_color='#2ca02c')
        fig.add_scatter(x=ts_df['period_label'], y=ts_df['bulk_orders'], name="ëŒ€ëŸ‰ ì£¼ë¬¸ìˆ˜", yaxis="y2", line=dict(color='#FF4B4B'))
        fig.update_layout(yaxis2=dict(overlaying="y", side="right"), template="plotly_white", hovermode="x unified")
        st.plotly_chart(fig, use_container_width=True)

        # [ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ì„¹ì…˜]
        st.markdown("---")
        st.subheader("ğŸ’¡ ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìš”ì•½")

        # ì£¼ìš” ì§€í‘œ ë³€í™”
        insights = []
        if curr['revenue'] > prev['revenue']:
            insights.append(f"ì´ ë§¤ì¶œì•¡ì´ ì „ê¸° ëŒ€ë¹„ {get_delta(curr['revenue'], prev['revenue'])} ì¦ê°€í–ˆìŠµë‹ˆë‹¤.")
        else:
            insights.append(f"ì´ ë§¤ì¶œì•¡ì´ ì „ê¸° ëŒ€ë¹„ {get_delta(curr['revenue'], prev['revenue'])} ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")

        if curr['orders'] > prev['orders']:
            insights.append(f"ì£¼ë¬¸ ìˆ˜ê°€ ì „ê¸° ëŒ€ë¹„ {get_delta(curr['orders'], prev['orders'])} ì¦ê°€í–ˆìŠµë‹ˆë‹¤.")
        else:
            insights.append(f"ì£¼ë¬¸ ìˆ˜ê°€ ì „ê¸° ëŒ€ë¹„ {get_delta(curr['orders'], prev['orders'])} ê°ì†Œí–ˆìŠµë‹ˆë‹¤.")

        # ëŒ€ëŸ‰ êµ¬ë§¤ ì˜í–¥
        insights.append(f"ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ ë¹„ì¤‘ì€ {b3.metric('dummy', 0)[0]}%ë¡œ ì „ì²´ ë§¤ì¶œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì°¸ê³  í•„ìš”.")

        # ì£¼ìš” ìœ ì… ì±„ë„ ìš”ì•½
        if source_df is not None and not source_df.empty:
            top_sources = ", ".join(source_df['source'].head(3).tolist())
            insights.append(f"ì£¼ìš” ìœ ì… ì±„ë„: {top_sources} (ë§¤ì¶œ ê¸°ì¤€)")

        # ì¹´ë“œ í˜•íƒœ ì¶œë ¥
        for insight in insights:
            st.info(insight)

else:
    st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
