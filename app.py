import streamlit as st
import google.generativeai as genai
from google.cloud import bigquery
import pandas as pd
import json
import datetime

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ AI Intelligence", page_icon="ğŸª‘", layout="wide")

# 2. ë³´ì•ˆ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„
try:
    # Secrets ì½ê¸°
    info = json.loads(st.secrets["gcp_service_account"]["json_key"])
    client = bigquery.Client.from_service_account_info(info)
    
    # Gemini API ì„¤ì •
    if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        # ê°€ì¥ ì•ˆì •ì ì¸ 1.5 Flash ëª¨ë¸ ì‚¬ìš©
        model = genai.GenerativeModel('gemini-1.5-flash') 
        st.sidebar.success("âœ… ì‹œë””ì¦ˆ ë¶„ì„ ì—”ì§„ ì—°ê²° ì™„ë£Œ", icon="ğŸš€")
    else:
        st.sidebar.error("âŒ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", icon="ğŸš¨")
        st.stop()

    # ë‚ ì§œ ìë™ ê³„ì‚°
    today = datetime.date.today().strftime('%Y%m%d')

    # 3. ë°ì´í„° ë¶„ì„ ì§€ì¹¨
    INSTRUCTION = """
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ëŒ€í‘œ ì˜ì ë¸Œëœë“œ 'ì‹œë””ì¦ˆ(SIDIZ)'ì˜ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ Google Analytics 4(GA4) BigQuery ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    
    [í™˜ê²½ ì •ë³´]
    - í”„ë¡œì íŠ¸ ID: """ + str(info['project_id']) + """
    - ë°ì´í„°ì…‹: analytics_324424314
    - í…Œì´ë¸”: events_*
    - ì˜¤ëŠ˜ ë‚ ì§œ: """ + today + """
    
    [ë‹µë³€ ê·œì¹™]
    1. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê¸° ìœ„í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
    2. ìƒì„±ëœ ì¿¼ë¦¬ì˜ ì˜ë¯¸ë¥¼ í•œê¸€ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    3. ê²°ê³¼ ë°ì´í„°ë¥¼ í•´ì„í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
    4. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    """

except Exception as e:
    st.error(f"ì´ˆê¸° ì„¤ì • ì˜¤ë¥˜: {e}", icon="ğŸ”¥")
    st.stop()

# 4. UI êµ¬ì„±
st.title("ğŸª‘ SIDIZ Data Intelligence Portal")
st.markdown("---")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë©”ì‹œì§€ ì €ì¥ìš©)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë° AI ì²˜ë¦¬
if prompt := st.chat_input("ë°ì´í„°ì—ê²Œ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”..."):
    # ì‚¬ìš©ì ì§ˆë¬¸ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ë¹„ì„œ ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë¹…ì¿¼ë¦¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                full_query = INSTRUCTION + "\n\nì‚¬ìš©ì ì§ˆë¬¸: " + prompt
                response = model.generate_content(full_query)
                
                if response and response.text:
                    answer = response.text
                    st.markdown(answer)
                    # ë‹µë³€ ì €ì¥
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                else:
                    st.error("AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                if "429" in str(e):
                    st.error("â³ í• ë‹¹ëŸ‰ ì´ˆê³¼: 1ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", icon="âš ï¸")
                else:
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", icon="ğŸš¨")
