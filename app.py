import streamlit as st
from google.cloud import bigquery
import pandas as pd
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ Intelligence Dashboard", layout="wide")

@st.cache_resource
def get_bq_client():
    try:
        info = json.loads(st.secrets["gcp_service_account"]["json_key"])
        return bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    except Exception as e:
        st.error(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

client = get_bq_client()

# -------------------------------------------------
# 2. ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (EASY REPAIR í•„í„°ë§ í¬í•¨)
# -------------------------------------------------
def get_dashboard_data(start_c, end_c, start_p, end_p, time_unit):
    if client is None: return None, None, None
    
    s_c, e_c = start_c.strftime('%Y%m%d'), end_c.strftime('%Y%m%d')
    s_p, e_p = start_p.strftime('%Y%m%d'), end_p.strftime('%Y%m%d')

    if time_unit == "ì¼ë³„": group_sql = "PARSE_DATE('%Y%m%d', event_date)"
    elif time_unit == "ì£¼ë³„": group_sql = "DATE_TRUNC(PARSE_DATE('%Y%m%d', event_date), WEEK)"
    else: group_sql = "DATE_TRUNC(PARSE_DATE('%Y%m%d', event_date), MONTH)"

    # í•µì‹¬ ì§€í‘œ ì¿¼ë¦¬
    query = f"""
    WITH base AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id, event_name, ecommerce.purchase_revenue, ecommerce.transaction_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num,
            items
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min(s_c, s_p)}' AND '{max(e_c, e_p)}'
    ),
    -- EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì‹ë³„ (í•˜ì´í”ˆ í¬í•¨)
    easy_repair_check AS (
        SELECT 
            transaction_id,
            -- ê° ì•„ì´í…œì´ EASY REPAIRì¸ì§€ í™•ì¸
            (UPPER(COALESCE(item.item_category, '')) LIKE '%EASY REPAIR%' OR
             UPPER(COALESCE(item.item_category, '')) LIKE '%EASY-REPAIR%') as is_easy_repair
        FROM base,
        UNNEST(items) as item
        WHERE event_name = 'purchase'
        GROUP BY transaction_id, item.item_id, item.item_category
    ),
-- EASY REPAIR(ì†Œëª¨í’ˆ)ë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì‹ë³„ (ë¡œì§ ëŒ€í­ ê°•í™”)
    easy_repair_only_orders AS (
        SELECT transaction_id
        FROM base, UNNEST(items) as item
        WHERE event_name = 'purchase'
        GROUP BY transaction_id
        HAVING LOGICAL_AND(
            -- 1. ì¹´í…Œê³ ë¦¬ì— EASY REPAIRê°€ í¬í•¨ë¨
            REGEXP_CONTAINS(UPPER(IFNULL(item.item_category, '')), r'EASY.REPAIR') OR 
            -- 2. ìƒí’ˆëª…ì— EASY REPAIRê°€ í¬í•¨ë¨
            REGEXP_CONTAINS(UPPER(IFNULL(item.item_name, '')), r'EASY.REPAIR') OR
            -- 3. ìƒ˜í”Œì—ì„œ í™•ì¸ëœ ì£¼ìš” ì†Œëª¨í’ˆ í‚¤ì›Œë“œë“¤ (í•„í„°ë§ í•µì‹¬)
            REGEXP_CONTAINS(item.item_name, r'íŒ¨ë“œ|í—¤ë“œë ˆìŠ¤íŠ¸|ì»¤ë²„|ë‹¤ë¦¬|ë°”í€´|ê¸€ë¼ì´ë“œ|ë¸”ë¡|ì¢ŒíŒ|ì´ì§€ë¦¬í˜ì–´')
        )
    )
    SELECT 
        CASE WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}') THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(sid AS STRING))) as sessions,
        COUNTIF(event_name = 'sign_up') as signups,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue,
        -- EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸
        COUNTIF(event_name = 'purchase' AND transaction_id NOT IN (SELECT transaction_id FROM easy_repair_only_orders)) as filtered_orders,
        SUM(CASE WHEN event_name = 'purchase' AND transaction_id NOT IN (SELECT transaction_id FROM easy_repair_only_orders) THEN purchase_revenue ELSE 0 END) as filtered_revenue
    FROM base 
    GROUP BY 1 
    HAVING type IS NOT NULL
    """

    # ì‹œê³„ì—´ ë°ì´í„°
    ts_query = f"""
    SELECT 
        CAST({group_sql} AS STRING) as period_label, 
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING))) as sessions,
        SUM(IFNULL(ecommerce.purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase') as orders
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
    GROUP BY 1 ORDER BY 1
    """

    try:
        return client.query(query).to_dataframe(), client.query(ts_query).to_dataframe()
    except Exception as e:
        st.error(f"âš ï¸ ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None

# -------------------------------------------------
# 3. ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì¶”ì¶œ (TOP3 + ì¦ê°ìœ¨)
# -------------------------------------------------
def get_insight_data(start_c, end_c, start_p, end_p):
    if client is None: return None
    
    s_c, e_c = start_c.strftime('%Y%m%d'), end_c.strftime('%Y%m%d')
    s_p, e_p = start_p.strftime('%Y%m%d'), end_p.strftime('%Y%m%d')
    
    # ì œí’ˆë³„ ë§¤ì¶œ ë³€í™” (TOP3)
    product_query = f"""
    WITH current_products AS (
        SELECT 
            item.item_name as product,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`,
        UNNEST(items) as item
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_products AS (
        SELECT 
            item.item_name as product,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`,
        UNNEST(items) as item
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.product, p.product) as product_name,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change,
        ROUND(SAFE_DIVIDE((IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) * 100, IFNULL(p.revenue, 0)), 1) as change_pct
    FROM current_products c
    FULL OUTER JOIN previous_products p ON c.product = p.product
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    LIMIT 10
    """
    
    # ì±„ë„ë³„ ë§¤ì¶œ ë³€í™” (TOP3)
    channel_query = f"""
    WITH current_channels AS (
        SELECT 
            CONCAT(traffic_source.source, ' / ', traffic_source.medium) as channel,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_channels AS (
        SELECT 
            CONCAT(traffic_source.source, ' / ', traffic_source.medium) as channel,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.channel, p.channel) as channel_name,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change,
        ROUND(SAFE_DIVIDE((IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) * 100, IFNULL(p.revenue, 0)), 1) as change_pct
    FROM current_channels c
    FULL OUTER JOIN previous_channels p ON c.channel = p.channel
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    LIMIT 10
    """
    
    # ì§€ì—­ë³„ ë³€í™”
    demo_query = f"""
    WITH current_demo AS (
        SELECT 
            CONCAT(IFNULL(geo.country, 'Unknown'), ' / ', IFNULL(geo.city, 'Unknown')) as location,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_demo AS (
        SELECT 
            CONCAT(IFNULL(geo.country, 'Unknown'), ' / ', IFNULL(geo.city, 'Unknown')) as location,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.location, p.location) as location_name,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change,
        ROUND(SAFE_DIVIDE((IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) * 100, IFNULL(p.revenue, 0)), 1) as change_pct
    FROM current_demo c
    FULL OUTER JOIN previous_demo p ON c.location = p.location
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    LIMIT 10
    """
    
    # ë””ë°”ì´ìŠ¤ë³„ ë³€í™”
    device_query = f"""
    WITH current_device AS (
        SELECT 
            device.category as device,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_device AS (
        SELECT 
            device.category as device,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.device, p.device) as device_name,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change,
        ROUND(SAFE_DIVIDE((IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) * 100, IFNULL(p.revenue, 0)), 1) as change_pct
    FROM current_device c
    FULL OUTER JOIN previous_device p ON c.device = p.device
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    """
    
# ì¸êµ¬í†µê³„ë³„ ë§¤ì¶œ ë³€í™” (ì„±ë³„&ì—°ë ¹ ì¡°í•©) - ê³ ì„±ëŠ¥/ì—ëŸ¬ë°©ì§€ ë²„ì „
    demographics_query = f"""
    WITH raw_purchase AS (
        SELECT 
            _TABLE_SUFFIX as suffix,
            ecommerce.purchase_revenue,
            -- event_paramsì™€ user_properties ì–‘ìª½ ëª¨ë‘ì—ì„œ ì¶”ì¶œ ì‹œë„
            COALESCE(
                (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'u_gender'),
                (SELECT value.string_value FROM UNNEST(user_properties) WHERE key = 'u_gender'),
                'Unknown'
            ) as gender_raw,
            COALESCE(
                (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'u_age'),
                (SELECT value.string_value FROM UNNEST(user_properties) WHERE key = 'u_age'),
                'Unknown'
            ) as age_raw
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min(s_c, s_p)}' AND '{max(e_c, e_p)}'
        AND event_name = 'purchase'
    ),
    processed_data AS (
        SELECT 
            suffix,
            purchase_revenue,
            CONCAT(
                CASE WHEN gender_raw = 'male' THEN 'ë‚¨ì„±' WHEN gender_raw = 'female' THEN 'ì—¬ì„±' ELSE gender_raw END,
                ' / ',
                age_raw
            ) as demographic
        FROM raw_purchase
        WHERE gender_raw != 'Unknown' OR age_raw != 'Unknown' -- ì •ë³´ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” ê²½ìš°ë§Œ
    )
    SELECT 
        demographic as demographic_name,
        SUM(CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN purchase_revenue ELSE 0 END) as current_revenue,
        SUM(CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN purchase_revenue ELSE 0 END) as previous_revenue,
        SUM(CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN purchase_revenue ELSE 0 END) - 
        SUM(CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN purchase_revenue ELSE 0 END) as revenue_change,
        ROUND(SAFE_DIVIDE(
            (SUM(CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN purchase_revenue ELSE 0 END) - SUM(CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN purchase_revenue ELSE 0 END)) * 100,
            SUM(CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN purchase_revenue ELSE 0 END)
        ), 1) as change_pct
    FROM processed_data
    GROUP BY 1
    ORDER BY ABS(revenue_change) DESC
    LIMIT 10
    """
    
    # ì±„ë„ë³„ ìœ ì…(ì„¸ì…˜) ë³€í™”
    channel_sessions_query = f"""
    WITH current_channels AS (
        SELECT 
            CONCAT(traffic_source.source, ' / ', traffic_source.medium) as channel,
            COUNT(DISTINCT CONCAT(
                user_pseudo_id, 
                CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING)
            )) as sessions
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        GROUP BY 1
    ),
    previous_channels AS (
        SELECT 
            CONCAT(traffic_source.source, ' / ', traffic_source.medium) as channel,
            COUNT(DISTINCT CONCAT(
                user_pseudo_id, 
                CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING)
            )) as sessions
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.channel, p.channel) as channel_name,
        IFNULL(c.sessions, 0) as current_sessions,
        IFNULL(p.sessions, 0) as previous_sessions,
        IFNULL(c.sessions, 0) - IFNULL(p.sessions, 0) as sessions_change,
        ROUND(SAFE_DIVIDE((IFNULL(c.sessions, 0) - IFNULL(p.sessions, 0)) * 100, IFNULL(p.sessions, 0)), 1) as change_pct
    FROM current_channels c
    FULL OUTER JOIN previous_channels p ON c.channel = p.channel
    ORDER BY ABS(IFNULL(c.sessions, 0) - IFNULL(p.sessions, 0)) DESC
    LIMIT 10
    """
    
# ì¸êµ¬í†µê³„ë³„ ìœ ì…(ì„¸ì…˜) ë³€í™” - ê³ ì„±ëŠ¥/ì—ëŸ¬ë°©ì§€ ë²„ì „
    demographics_sessions_query = f"""
    WITH raw_sessions AS (
        SELECT 
            _TABLE_SUFFIX as suffix,
            user_pseudo_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') as sid,
            COALESCE(
                (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'u_gender'),
                (SELECT value.string_value FROM UNNEST(user_properties) WHERE key = 'u_gender'),
                'Unknown'
            ) as gender_raw,
            COALESCE(
                (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'u_age'),
                (SELECT value.string_value FROM UNNEST(user_properties) WHERE key = 'u_age'),
                'Unknown'
            ) as age_raw
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min(s_c, s_p)}' AND '{max(e_c, e_p)}'
    ),
    processed_sessions AS (
        SELECT 
            suffix,
            CONCAT(user_pseudo_id, CAST(sid AS STRING)) as session_id,
            CONCAT(
                CASE WHEN gender_raw = 'male' THEN 'ë‚¨ì„±' WHEN gender_raw = 'female' THEN 'ì—¬ì„±' ELSE gender_raw END,
                ' / ',
                age_raw
            ) as demographic
        FROM raw_sessions
        WHERE gender_raw != 'Unknown' OR age_raw != 'Unknown'
    )
    SELECT 
        demographic as demographic_name,
        COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN session_id END) as current_sessions,
        COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN session_id END) as previous_sessions,
        COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN session_id END) - 
        COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN session_id END) as sessions_change,
        ROUND(SAFE_DIVIDE(
            (COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN session_id END) - COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN session_id END)) * 100,
            COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN session_id END)
        ), 1) as change_pct
    FROM processed_sessions
    GROUP BY 1
    ORDER BY ABS(sessions_change) DESC
    LIMIT 10
    """
        
        # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½ (ì¿¼ë¦¬ í›„)
        product_df.columns = ['ì œí’ˆëª…', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        channel_df.columns = ['ì±„ë„', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        demo_df.columns = ['ì§€ì—­', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        device_df.columns = ['ë””ë°”ì´ìŠ¤', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        demographics_df.columns = ['ì¸êµ¬í†µê³„', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        channel_sessions_df.columns = ['ì±„ë„', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì¦ê°ìœ¨']
        demographics_sessions_df.columns = ['ì¸êµ¬í†µê³„', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì¦ê°ìœ¨']
        
        return {
            'product': product_df,
            'channel_revenue': channel_df,
            'channel_sessions': channel_sessions_df,
            'demo': demo_df,
            'device': device_df,
            'demographics_revenue': demographics_df,
            'demographics_sessions': demographics_sessions_df
        }
    except Exception as e:
        st.error(f"âš ï¸ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì˜¤ë¥˜: {e}")
        return None

# -------------------------------------------------
# 4. ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
# -------------------------------------------------
def generate_insights(curr, prev, insight_data):
    insights = []
    
    # 1. ì „ì²´ ë§¤ì¶œ ë³€ë™
    rev_change = curr['revenue'] - prev['revenue']
    rev_pct = (rev_change / prev['revenue'] * 100) if prev['revenue'] > 0 else 0
    
    if abs(rev_pct) > 3:
        direction = "ì¦ê°€" if rev_change > 0 else "ê°ì†Œ"
        insights.append(f"### ğŸ“Š ì „ì²´ ë§¤ì¶œ {direction}")
        insights.append(f"ë§¤ì¶œì´ **â‚©{abs(rev_change):,.0f} ({abs(rev_pct):.1f}%) {direction}**í–ˆìŠµë‹ˆë‹¤.")
    
    # 2. ì œí’ˆ ì˜í–¥ (TOP3)
    if insight_data and 'product' in insight_data and not insight_data['product'].empty:
        insights.append(f"\n### ğŸ† ì£¼ìš” ì œí’ˆ ì˜í–¥ TOP3")
        for idx, row in insight_data['product'].head(3).iterrows():
            if abs(row['ë§¤ì¶œë³€í™”']) > 500000:
                direction = "â†‘" if row['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì œí’ˆëª…']}** {direction} â‚©{abs(row['ë§¤ì¶œë³€í™”']):,.0f} ({row['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 3. ì±„ë„ ë§¤ì¶œ ì˜í–¥ (TOP3)
    if insight_data and 'channel_revenue' in insight_data and not insight_data['channel_revenue'].empty:
        insights.append(f"\n### ğŸ¯ ì£¼ìš” ì±„ë„ ë§¤ì¶œ ì˜í–¥ TOP3")
        for idx, row in insight_data['channel_revenue'].head(3).iterrows():
            if abs(row['ë§¤ì¶œë³€í™”']) > 300000:
                direction = "â†‘" if row['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì±„ë„']}** {direction} â‚©{abs(row['ë§¤ì¶œë³€í™”']):,.0f} ({row['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 4. ì±„ë„ ìœ ì… ì˜í–¥ (TOP3)
    if insight_data and 'channel_sessions' in insight_data and not insight_data['channel_sessions'].empty:
        insights.append(f"\n### ğŸšª ì£¼ìš” ì±„ë„ ìœ ì… ì˜í–¥ TOP3")
        for idx, row in insight_data['channel_sessions'].head(3).iterrows():
            if abs(row['ì„¸ì…˜ë³€í™”']) > 100:
                direction = "â†‘" if row['ì„¸ì…˜ë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì±„ë„']}** {direction} {abs(row['ì„¸ì…˜ë³€í™”']):,.0f}ì„¸ì…˜ ({row['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 5. ì¸êµ¬í†µê³„ ë§¤ì¶œ ì˜í–¥ (TOP3)
    if insight_data and 'demographics_revenue' in insight_data and not insight_data['demographics_revenue'].empty:
        insights.append(f"\n### ğŸ‘¥ ì¸êµ¬í†µê³„ ë§¤ì¶œ ì˜í–¥ TOP3")
        for idx, row in insight_data['demographics_revenue'].head(3).iterrows():
            if abs(row['ë§¤ì¶œë³€í™”']) > 300000:
                direction = "â†‘" if row['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì¸êµ¬í†µê³„']}** {direction} â‚©{abs(row['ë§¤ì¶œë³€í™”']):,.0f} ({row['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 6. ì¸êµ¬í†µê³„ ìœ ì… ì˜í–¥ (TOP3)
    if insight_data and 'demographics_sessions' in insight_data and not insight_data['demographics_sessions'].empty:
        insights.append(f"\n### ğŸš¶ ì¸êµ¬í†µê³„ ìœ ì… ì˜í–¥ TOP3")
        for idx, row in insight_data['demographics_sessions'].head(3).iterrows():
            if abs(row['ì„¸ì…˜ë³€í™”']) > 100:
                direction = "â†‘" if row['ì„¸ì…˜ë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì¸êµ¬í†µê³„']}** {direction} {abs(row['ì„¸ì…˜ë³€í™”']):,.0f}ì„¸ì…˜ ({row['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 7. ëŒ€ëŸ‰ êµ¬ë§¤ ì˜í–¥
    bulk_change = curr['bulk_revenue'] - prev['bulk_revenue']
    bulk_pct = (bulk_change / prev['bulk_revenue'] * 100) if prev['bulk_revenue'] > 0 else 0
    
    if abs(bulk_pct) > 10 or abs(bulk_change) > 5000000:
        direction = "ì¦ê°€" if bulk_change > 0 else "ê°ì†Œ"
        insights.append(f"\n### ğŸ’¼ ëŒ€ëŸ‰ êµ¬ë§¤ ì˜í–¥")
        insights.append(f"ëŒ€ëŸ‰ êµ¬ë§¤(150ë§Œì›â†‘) ë§¤ì¶œì´ **â‚©{abs(bulk_change):,.0f} ({abs(bulk_pct):.1f}%) {direction}**í–ˆìŠµë‹ˆë‹¤.")
    
    # 8. ì§€ì—­ ë³€í™”
    if insight_data and 'demo' in insight_data and not insight_data['demo'].empty:
        top_demo = insight_data['demo'].iloc[0]
        if abs(top_demo['ë§¤ì¶œë³€í™”']) > 1000000:
            direction = "â†‘" if top_demo['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
            insights.append(f"\n### ğŸŒ ì§€ì—­ë³„ ë³€í™”")
            insights.append(f"**{top_demo['ì§€ì—­']}** {direction} â‚©{abs(top_demo['ë§¤ì¶œë³€í™”']):,.0f} ({top_demo['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 9. ì „í™˜ìœ¨ ë³€í™”
    curr_cr = (curr['orders'] / curr['sessions'] * 100) if curr['sessions'] > 0 else 0
    prev_cr = (prev['orders'] / prev['sessions'] * 100) if prev['sessions'] > 0 else 0
    cr_change = curr_cr - prev_cr
    
    if abs(cr_change) > 0.15:
        direction = "ê°œì„ " if cr_change > 0 else "í•˜ë½"
        insights.append(f"\n### ğŸ¯ êµ¬ë§¤ ì „í™˜ìœ¨ {direction}")
        insights.append(f"ì „í™˜ìœ¨ì´ **{abs(cr_change):.2f}%p {direction}**í–ˆìŠµë‹ˆë‹¤ ({prev_cr:.2f}% â†’ {curr_cr:.2f}%).")
    
    return "\n".join(insights) if insights else "ğŸ“Š ì „ê¸° ëŒ€ë¹„ í° ë³€í™”ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

# -------------------------------------------------
# 5. ë©”ì¸ UI
# -------------------------------------------------
st.title("ğŸª‘ SIDIZ AI Intelligence Dashboard")

today = datetime.now()
with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    curr_date = st.date_input("ë¶„ì„ ê¸°ê°„", [today - timedelta(days=7), today - timedelta(days=1)])
    comp_date = st.date_input("ë¹„êµ ê¸°ê°„", [today - timedelta(days=14), today - timedelta(days=8)])
    time_unit = st.selectbox("ì¶”ì´ ë¶„ì„ ë‹¨ìœ„", ["ì¼ë³„", "ì£¼ë³„", "ì›”ë³„"])

if len(curr_date) == 2 and len(comp_date) == 2:
    summary_df, ts_df = get_dashboard_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1], time_unit)
    
    if summary_df is not None and not summary_df.empty:
        curr = summary_df[summary_df['type'] == 'Current'].iloc[0]
        prev = summary_df[summary_df['type'] == 'Previous'].iloc[0] if 'Previous' in summary_df['type'].values else curr

        def get_delta(c, p):
            if p == 0: return "0%"
            return f"{((c - p) / p * 100):+.1f}%"

        # [10ëŒ€ ì§€í‘œ - 2ì¤„ 5ê°œì”©]
        st.subheader("ğŸ¯ í•µì‹¬ ì„±ê³¼ ìš”ì•½")
        
        # ì²« ë²ˆì§¸ ì¤„ (5ê°œ)
        cols = st.columns(5)
        cols[0].metric("í™œì„± ì‚¬ìš©ì", f"{int(curr['users']):,}ëª…", get_delta(curr['users'], prev['users']))
        cols[1].metric("ì‹ ê·œ ì‚¬ìš©ì", f"{int(curr['new_users']):,}ëª…", get_delta(curr['new_users'], prev['new_users']))
        cols[2].metric("ì„¸ì…˜ ìˆ˜", f"{int(curr['sessions']):,}", get_delta(curr['sessions'], prev['sessions']))
        cols[3].metric("íšŒì›ê°€ì…", f"{int(curr['signups']):,}ê±´", get_delta(curr['signups'], prev['signups']))
        
        c_nv = (curr['new_users']/curr['users']*100) if curr['users'] > 0 else 0
        p_nv = (prev['new_users']/prev['users']*100) if prev['users'] > 0 else 0
        cols[4].metric("ì‹ ê·œ ë°©ë¬¸ìœ¨", f"{c_nv:.1f}%", f"{c_nv-p_nv:+.1f}%p")
        
        # ë‘ ë²ˆì§¸ ì¤„ (5ê°œ)
        cols = st.columns(5)
        cols[0].metric("ì£¼ë¬¸ ìˆ˜", f"{int(curr['orders']):,}ê±´", get_delta(curr['orders'], prev['orders']))
        cols[1].metric("ì´ ë§¤ì¶œì•¡", f"â‚©{int(curr['revenue']):,}", get_delta(curr['revenue'], prev['revenue']))
        
        c_cr = (curr['orders']/curr['sessions']*100) if curr['sessions'] > 0 else 0
        p_cr = (prev['orders']/prev['sessions']*100) if prev['sessions'] > 0 else 0
        cols[2].metric("êµ¬ë§¤ ì „í™˜ìœ¨", f"{c_cr:.2f}%", f"{c_cr-p_cr:+.2f}%p")
        
        c_aov = (curr['revenue']/curr['orders']) if curr['orders'] > 0 else 0
        p_aov = (prev['revenue']/prev['orders']) if prev['orders'] > 0 else 0
        cols[3].metric("í‰ê·  ê°ë‹¨ê°€", f"â‚©{int(c_aov):,}", get_delta(c_aov, p_aov))
        
        # EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸ ê°ë‹¨ê°€
        c_filtered_aov = (curr['filtered_revenue']/curr['filtered_orders']) if curr.get('filtered_orders', 0) > 0 else 0
        p_filtered_aov = (prev['filtered_revenue']/prev['filtered_orders']) if prev.get('filtered_orders', 0) > 0 else 0
        
        if c_filtered_aov > 0:
            cols[4].metric("í•„í„°ë§ ê°ë‹¨ê°€", f"â‚©{int(c_filtered_aov):,}", get_delta(c_filtered_aov, p_filtered_aov), 
                          help="EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸")
        else:
            cols[4].metric("í•„í„°ë§ ê°ë‹¨ê°€", "ë°ì´í„° ì—†ìŒ", help="EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸")

        # [ëŒ€ëŸ‰ êµ¬ë§¤]
        st.markdown("---")
        st.subheader("ğŸ“¦ ëŒ€ëŸ‰ êµ¬ë§¤ ì„¸ê·¸ë¨¼íŠ¸ (150ë§Œ ì›â†‘)")
        b1, b2, b3 = st.columns(3)
        b1.metric("ëŒ€ëŸ‰ ì£¼ë¬¸ ê±´ìˆ˜", f"{int(curr['bulk_orders'])}ê±´", f"{int(curr['bulk_orders'] - prev['bulk_orders']):+}ê±´")
        b2.metric("ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ", f"â‚©{int(curr['bulk_revenue']):,}", get_delta(curr['bulk_revenue'], prev['bulk_revenue']))
        b3.metric("ëŒ€ëŸ‰ ë§¤ì¶œ ë¹„ì¤‘", f"{(curr['bulk_revenue']/curr['revenue']*100 if curr['revenue']>0 else 0):.1f}%")

        # [ê°œì„ ëœ ë§¤ì¶œ ì¶”ì´ ì°¨íŠ¸]
        st.markdown("---")
        st.subheader(f"ğŸ“Š {time_unit} ë§¤ì¶œ ì¶”ì´")
        
        if ts_df is not None and not ts_df.empty:
            ts_df['conversion_rate'] = (ts_df['orders'] / ts_df['sessions'] * 100).fillna(0)
            
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            
            # ì„¸ì…˜ ìˆ˜ (ì„  ê·¸ë˜í”„)
            fig.add_trace(
                go.Scatter(
                    x=ts_df['period_label'], 
                    y=ts_df['sessions'], 
                    name="ì„¸ì…˜ ìˆ˜",
                    line=dict(color='#4A90E2', width=3),
                    mode='lines+markers',
                    marker=dict(size=8)
                ),
                secondary_y=False
            )
            
            # ë§¤ì¶œì•¡ (ë§‰ëŒ€ ê·¸ë˜í”„)
            fig.add_trace(
                go.Bar(
                    x=ts_df['period_label'], 
                    y=ts_df['revenue'], 
                    name="ë§¤ì¶œì•¡",
                    marker_color='#50C878',
                    opacity=0.7,
                    text=ts_df['revenue'].apply(lambda x: f'â‚©{x/1000000:.1f}M'),
                    textposition='outside'
                ),
                secondary_y=True
            )
            
            # ì „í™˜ìœ¨ (ì ì„ )
            fig.add_trace(
                go.Scatter(
                    x=ts_df['period_label'], 
                    y=ts_df['conversion_rate'], 
                    name="êµ¬ë§¤ ì „í™˜ìœ¨",
                    line=dict(color='#FF6B6B', width=2, dash='dash'),
                    mode='lines+markers',
                    marker=dict(size=6)
                ),
                secondary_y=False
            )
            
            fig.update_xaxes(title_text="ê¸°ê°„", showgrid=True, gridwidth=1, gridcolor='#E8E8E8')
            fig.update_yaxes(title_text="<b>ì„¸ì…˜ ìˆ˜ / ì „í™˜ìœ¨ (%)</b>", secondary_y=False, showgrid=True, gridwidth=1, gridcolor='#E8E8E8')
            fig.update_yaxes(title_text="<b>ë§¤ì¶œì•¡ (ì›)</b>", secondary_y=True)
            
            fig.update_layout(
                template="plotly_white",
                hovermode="x unified",
                font=dict(size=13, family="Pretendard, -apple-system, sans-serif"),
                legend=dict(
                    orientation="h", 
                    yanchor="bottom", 
                    y=1.02, 
                    xanchor="center", 
                    x=0.5,
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="#CCCCCC",
                    borderwidth=1
                ),
                plot_bgcolor='#FAFAFA',
                height=450
            )
            
            st.plotly_chart(fig, use_container_width=True)

        # [ë°ì´í„° ì¸ì‚¬ì´íŠ¸]
        st.markdown("---")
        st.subheader("ğŸ§  ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸")
        
        with st.spinner("ë¶„ì„ ì¤‘..."):
            insight_data = get_insight_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1])
            insights = generate_insights(curr, prev, insight_data)
            st.markdown(insights)
            
            # [ê°œì„ ëœ ìƒì„¸ ë°ì´í„° í…Œì´ë¸”]
            with st.expander("ğŸ“‹ ìƒì„¸ ë¶„ì„ ë°ì´í„° ë³´ê¸°"):
                if insight_data:
                    tab1, tab2, tab3, tab4, tab5 = st.tabs([
                        "ì œí’ˆë³„ ë¶„ì„", 
                        "ì±„ë„ë³„ ë¶„ì„",
                        "ì¸êµ¬í†µê³„ë³„ ë¶„ì„",
                        "ì§€ì—­ë³„ ë¶„ì„", 
                        "ë””ë°”ì´ìŠ¤ë³„ ë¶„ì„"
                    ])
                    
                    # ìˆ«ì í¬ë§· í•¨ìˆ˜
                    def format_currency(val):
                        return f"â‚©{val:,.0f}"
                    
                    def format_number(val):
                        return f"{val:,.0f}"
                    
                    def format_percent(val):
                        return f"{val:+.1f}%" if pd.notna(val) else "-"
                    
                    with tab1:
                        df = insight_data['product'].copy()
                        df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                        df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                        df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                        df['ì¦ê°ìœ¨'] = df['ì¦ê°ìœ¨'].apply(format_percent)
                        st.dataframe(df, use_container_width=True, height=400)
                    
                    with tab2:
                        # ì±„ë„ ë§¤ì¶œ ë°ì´í„°
                        df_rev = insight_data['channel_revenue'].copy()
                        df_rev = df_rev.rename(columns={'ì±„ë„': 'ì±„ë„ëª…'})
                        
                        # ì±„ë„ ì„¸ì…˜ ë°ì´í„°
                        df_ses = insight_data['channel_sessions'].copy()
                        df_ses = df_ses.rename(columns={'ì±„ë„': 'ì±„ë„ëª…'})
                        
                        # ë‘ ë°ì´í„° í•©ì¹˜ê¸°
                        df = pd.merge(df_rev, df_ses, on='ì±„ë„ëª…', how='outer', suffixes=('_ë§¤ì¶œ', '_ì„¸ì…˜'))
                        
                        # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬
                        df = df[['ì±„ë„ëª…', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨_ë§¤ì¶œ', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì¦ê°ìœ¨_ì„¸ì…˜']]
                        df = df.rename(columns={'ì¦ê°ìœ¨_ë§¤ì¶œ': 'ë§¤ì¶œì¦ê°ìœ¨', 'ì¦ê°ìœ¨_ì„¸ì…˜': 'ì„¸ì…˜ì¦ê°ìœ¨'})
                        
                        # í¬ë§· ì ìš©
                        df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                        df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                        df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                        df['ë§¤ì¶œì¦ê°ìœ¨'] = df['ë§¤ì¶œì¦ê°ìœ¨'].apply(format_percent)
                        df['í˜„ì¬ì„¸ì…˜'] = df['í˜„ì¬ì„¸ì…˜'].apply(format_number)
                        df['ì´ì „ì„¸ì…˜'] = df['ì´ì „ì„¸ì…˜'].apply(format_number)
                        df['ì„¸ì…˜ë³€í™”'] = df['ì„¸ì…˜ë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_number(abs(x))}")
                        df['ì„¸ì…˜ì¦ê°ìœ¨'] = df['ì„¸ì…˜ì¦ê°ìœ¨'].apply(format_percent)
                        
                        st.dataframe(df, use_container_width=True, height=400)
                    
                    with tab3:
                        # ì¸êµ¬í†µê³„ ë§¤ì¶œ ë°ì´í„°
                        df_rev = insight_data['demographics_revenue'].copy()
                        df_rev = df_rev.rename(columns={'ì¸êµ¬í†µê³„': 'ì¸êµ¬í†µê³„'})
                        
                        # ì¸êµ¬í†µê³„ ì„¸ì…˜ ë°ì´í„°
                        df_ses = insight_data['demographics_sessions'].copy()
                        df_ses = df_ses.rename(columns={'ì¸êµ¬í†µê³„': 'ì¸êµ¬í†µê³„'})
                        
                        # ë‘ ë°ì´í„° í•©ì¹˜ê¸°
                        df = pd.merge(df_rev, df_ses, on='ì¸êµ¬í†µê³„', how='outer', suffixes=('_ë§¤ì¶œ', '_ì„¸ì…˜'))
                        
                        # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬
                        df = df[['ì¸êµ¬í†µê³„', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨_ë§¤ì¶œ', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì¦ê°ìœ¨_ì„¸ì…˜']]
                        df = df.rename(columns={'ì¦ê°ìœ¨_ë§¤ì¶œ': 'ë§¤ì¶œì¦ê°ìœ¨', 'ì¦ê°ìœ¨_ì„¸ì…˜': 'ì„¸ì…˜ì¦ê°ìœ¨'})
                        
                        # í¬ë§· ì ìš©
                        df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                        df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                        df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                        df['ë§¤ì¶œì¦ê°ìœ¨'] = df['ë§¤ì¶œì¦ê°ìœ¨'].apply(format_percent)
                        df['í˜„ì¬ì„¸ì…˜'] = df['í˜„ì¬ì„¸ì…˜'].apply(format_number)
                        df['ì´ì „ì„¸ì…˜'] = df['ì´ì „ì„¸ì…˜'].apply(format_number)
                        df['ì„¸ì…˜ë³€í™”'] = df['ì„¸ì…˜ë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_number(abs(x))}")
                        df['ì„¸ì…˜ì¦ê°ìœ¨'] = df['ì„¸ì…˜ì¦ê°ìœ¨'].apply(format_percent)
                        
                        st.dataframe(df, use_container_width=True, height=400)
                    
                    with tab4:
                        df = insight_data['demo'].copy()
                        df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                        df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                        df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                        df['ì¦ê°ìœ¨'] = df['ì¦ê°ìœ¨'].apply(format_percent)
                        st.dataframe(df, use_container_width=True, height=400)
                    
                    with tab5:
                        df = insight_data['device'].copy()
                        df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                        df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                        df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                        df['ì¦ê°ìœ¨'] = df['ì¦ê°ìœ¨'].apply(format_percent)
                        st.dataframe(df, use_container_width=True, height=400)

else:
    st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
