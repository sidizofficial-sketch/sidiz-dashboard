import streamlit as st
import google.generativeai as genai
from google.cloud import bigquery
import pandas as pd
import json
import datetime
import re
import plotly.express as px
import plotly.graph_objects as go # ê³ ê¸‰ ì‹œê°í™”ìš© ì¶”ê°€

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ AI Intelligence", page_icon="ğŸª‘", layout="wide")

# 2. ë³´ì•ˆ ë° ëª¨ë¸ ì„¤ì •
try:
    info = json.loads(st.secrets["gcp_service_account"]["json_key"])
    client = bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    
    if "gemini" in st.secrets:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        target_model = next((m for m in models if "1.5-flash" in m), models[0])
        model = genai.GenerativeModel(target_model)

    project_id = info['project_id']
    dataset_id = "analytics_487246344"
    # ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ í’€ë„¤ì„ í…Œì´ë¸” ê²½ë¡œ ì •ì˜
    table_path = f"`{project_id}.{dataset_id}.events_*`"

    # AIì—ê²Œ ë¶„ì„ ëª…ì„¸ì„œ ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ë¶€ì—¬ (5ëŒ€ ì§€í‘œ í¬í•¨)
    INSTRUCTION = f"""
    ë‹¹ì‹ ì€ SIDIZì˜ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì œí’ˆ ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ ê°€ì´ë“œë¥¼ ì¤€ìˆ˜í•˜ì„¸ìš”.
    1. ë°˜ë“œì‹œ ```sql ... ``` ë¸”ë¡ì— BigQuery SQLì„ í¬í•¨í•˜ì„¸ìš”. í…Œì´ë¸”ì€ ë°˜ë“œì‹œ {table_path}ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    2. SQL ì‘ì„± ì‹œ ì¸êµ¬í†µê³„(age, gender), ìœ ì…ê²½ë¡œ(source/medium), ë§¤ì¶œ/ìˆ˜ëŸ‰, ì„œë¹„ìŠ¤ ì´ìš© í–‰íƒœ(ì´ë²¤íŠ¸ëª…)ë¥¼ ëª¨ë‘ í¬í•¨í•˜ë„ë¡ ì¿¼ë¦¬í•˜ì„¸ìš”.
    3. ê²°ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ 3ì¤„ ìš”ì•½í•˜ì„¸ìš”.
    4. ìƒí’ˆ í•„í„°ë§ ì‹œ UNNEST(items)ë¥¼ ì‚¬ìš©í•˜ê³  LIKE ì—°ì‚°ìë¡œ ì œí’ˆëª…ì„ ì°¾ìœ¼ì„¸ìš”.
    """

except Exception as e:
    st.error(f"ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# 3. UI êµ¬ì„±
st.title("ğŸª‘ SIDIZ AI Data Dashboard")
st.caption("SIDIZ GA4 ë¹…ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì‹œê°„ ì¸í…”ë¦¬ì „ìŠ¤ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# 4. ì‹¤í–‰ ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: T50 êµ¬ë§¤ìë“¤ì˜ íŠ¹ì§•ê³¼ ìœ ì… ê²½ë¡œ ë¶„ì„í•´ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            with st.spinner("ë¹…ë°ì´í„° ë¶„ì„ ì—”ì§„ ê°€ë™ ì¤‘..."):
                response = model.generate_content(f"{INSTRUCTION}\n\nì§ˆë¬¸: {prompt}")
                answer = response.text
                
                # ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ì¶œë ¥
                st.markdown("### ğŸ’¡ AI ì¸ì‚¬ì´íŠ¸ ìš”ì•½")
