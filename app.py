import streamlit as st
from google.cloud import bigquery
import pandas as pd
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
import google.generativeai as genai

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ Analytics", layout="wide")

# Gemini ì„¤ì • (Secrets í‚¤ ëª…ì¹­ í™•ì¸ í•„ìš”)
if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
    genai.configure(api_key=st.secrets["gemini"]["api_key"])
    model = genai.GenerativeModel('gemini-1.5-flash')
    HAS_GEMINI = True
else:
    HAS_GEMINI = False

# 2. BigQuery í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
@st.cache_resource
def get_bq_client():
    try:
        # st.secrets êµ¬ì¡°ì— ë”°ë¼ ì ‘ê·¼ ë°©ì‹ ìˆ˜ì •
        if "gcp_service_account" in st.secrets:
            info = dict(st.secrets["gcp_service_account"])
            # JSON ë‚´ë¶€ í•„ë“œê°€ ë¬¸ìì—´ë¡œ ë°•í˜€ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            if "json_key" in info:
                info = json.loads(info["json_key"])
            return bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    except Exception as e:
        st.error(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

client = get_bq_client()

# 3. ìƒí’ˆëª… ì •ì œ ë¡œì§
def clean_product_name(name):
    if not name: return name
    for char in [' - ', ' / ', ' (']:
        if char in name:
            name = name.split(char)[0]
    return name.strip()

@st.cache_data(ttl=3600)
def get_master_item_list():
    if client is None: return pd.DataFrame(columns=['clean_name'])
    # _TABLE_SUFFIXë¥¼ STRINGìœ¼ë¡œ ë¹„êµí•˜ì—¬ ì†ë„ í–¥ìƒ
    query = """
    SELECT DISTINCT item.item_name 
    FROM `sidiz-458301.analytics_487246344.events_*`, UNNEST(items) as item
    WHERE _TABLE_SUFFIX >= FORMAT_DATE('%Y%m%d', DATE_SUB(CURRENT_DATE(), INTERVAL 90 DAY))
    AND item.item_name IS NOT NULL AND item.item_name NOT IN ('(not set)', '')
    """
    try:
        df = client.query(query).to_dataframe()
        df['clean_name'] = df['item_name'].apply(clean_product_name)
        return df[['clean_name']].drop_duplicates().sort_values('clean_name')
    except Exception as e:
        st.sidebar.error(f"ìƒí’ˆ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(columns=['clean_name'])

# 4. ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (ì—ëŸ¬ ìƒì„¸ ì¶œë ¥ ì¶”ê°€)
def get_kpi_data(start_c, end_c, start_p, end_p):
    s_c = start_c.strftime('%Y%m%d')
    e_c = end_c.strftime('%Y%m%d')
    
    # ê¸°ë³¸ ì¿¼ë¦¬ (Canonical ì‘ì—… ì „ì´ë¯€ë¡œ ì›ë³¸ í™œìš©)
    query = f"""
    SELECT 
        '{start_c}' as period_start,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING))) as sessions,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(ecommerce.purchase_revenue) as revenue
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
    """
    
    if start_p and end_p:
        s_p = start_p.strftime('%Y%m%d')
        e_p = end_p.strftime('%Y%m%d')
        query = f"({query}) UNION ALL (SELECT '{start_p}', COUNT(DISTINCT user_pseudo_id), COUNT(DISTINCT CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING))), COUNTIF(event_name = 'purchase'), SUM(ecommerce.purchase_revenue) FROM `sidiz-458301.analytics_487246344.events_*` WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}')"
    
    try:
        return client.query(query).to_dataframe()
    except Exception as e:
        # í•œì ì˜¤ë¥˜/Redacted ë°©ì§€ë¥¼ ìœ„í•´ ìƒì„¸ ì—ëŸ¬ ê°•ì œ ì¶œë ¥
        st.error("ğŸš¨ BigQuery ì¿¼ë¦¬ ì‹¤í–‰ ì—ëŸ¬ ë°œìƒ")
        st.code(str(e)) # ì—¬ê¸°ì„œ ì‹¤ì œ ì›ì¸ì´ ë‚˜ì˜µë‹ˆë‹¤.
        return pd.DataFrame()

# 5. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“… ê¸°ê°„ ì„¤ì •")
    yesterday = datetime.now() - timedelta(days=1)
    seven_days_ago = yesterday - timedelta(days=6)
    curr_d = st.date_input("ë¶„ì„ ê¸°ê°„ (Current)", [seven_days_ago, yesterday])
    
    use_compare = st.checkbox("ë¹„êµ ê¸°ê°„ ì‚¬ìš© (Previous)")
    comp_d = [None, None]
    if use_compare:
        comp_d = st.date_input("ë¹„êµ ê¸°ê°„ ì„ íƒ", [seven_days_ago - timedelta(days=7), yesterday - timedelta(days=7)])

    st.markdown("---")
    st.header("ğŸ” ì œí’ˆ í•„í„°")
    master_items = get_master_item_list()
    search_kw = st.text_input("ì œí’ˆëª… í‚¤ì›Œë“œ ê²€ìƒ‰", value="T50")
    
    selected_names = []
    if not master_items.empty:
        filtered = master_items[master_items['clean_name'].str.contains(search_kw, case=False, na=False)]
        selected_names = st.multiselect("ë¶„ì„í•  ìƒí’ˆëª… ì„ íƒ", options=filtered['clean_name'].unique())

# 6. ë©”ì¸ í™”ë©´
tab1, tab2 = st.tabs(["ğŸ“Š ì „ì²´ KPI í˜„í™©", "ğŸª‘ ì œí’ˆë³„ ìƒì„¸ ë¶„ì„"])

with tab1:
    if len(curr_d) == 2:
        kpi_res = get_kpi_data(curr_d[0], curr_d[1], comp_d[0] if use_compare else None, comp_d[1] if use_compare else None)
        
        if not kpi_res.empty:
            curr = kpi_res.iloc[0]
            prev = kpi_res.iloc[1] if len(kpi_res) > 1 else curr
            
            st.subheader("ğŸ¯ í•µì‹¬ ì„±ê³¼ ìš”ì•½")
            c1, c2, c3, c4 = st.columns(4)
            
            def delta(c, p):
                if not use_compare or p == 0: return None
                return f"{((float(c)-float(p))/float(p)*100):+.1f}%"

            c1.metric("ë§¤ì¶œì•¡", f"â‚©{int(curr['revenue'] or 0):,}", delta(curr['revenue'], prev['revenue']))
            c2.metric("ì£¼ë¬¸ìˆ˜", f"{int(curr['orders']):,}", delta(curr['orders'], prev['orders']))
            c3.metric("ì„¸ì…˜", f"{int(curr['sessions']):,}", delta(curr['sessions'], prev['sessions']))
            cvR = (curr['orders']/curr['sessions']*100) if curr['sessions'] > 0 else 0
            c4.metric("êµ¬ë§¤ì „í™˜ìœ¨", f"{cvR:.2f}%")
            
            # AI ë¶„ì„ ì¶”ê°€ (ì›í•˜ì‹¤ ê²½ìš°)
            if HAS_GEMINI and st.button("AI ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"):
                with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
                    res = model.generate_content(f"ë‹¤ìŒ ì‹œë””ì¦ˆ ì§€í‘œë¥¼ ë¶„ì„í•´ì¤˜: ë§¤ì¶œ â‚©{curr['revenue']}, ì£¼ë¬¸ {curr['orders']}, ì„¸ì…˜ {curr['sessions']}")
                    st.info(res.text)
        else:
            st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìœ„ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

with tab2:
    if not selected_names:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ìƒí’ˆëª…ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        # ìƒí’ˆëª… ì¿¼ë¦¬ ë³´ì •
        name_filters = " OR ".join([f"item.item_name LIKE '{n}%'" for n in selected_names])
        p_query = f"""
            SELECT 
                item.item_name, 
                COUNTIF(event_name='view_item') as views, 
                COUNTIF(event_name='purchase') as orders, 
                SUM(item.item_revenue) as revenue
            FROM `sidiz-458301.analytics_487246344.events_*`, UNNEST(items) as item
            WHERE _TABLE_SUFFIX BETWEEN '{curr_d[0].strftime('%Y%m%d')}' AND '{curr_d[1].strftime('%Y%m%d')}'
            AND ({name_filters})
            GROUP BY 1 ORDER BY revenue DESC
        """
        try:
            res_df = client.query(p_query).to_dataframe()
            if not res_df.empty:
                res_df['item_name'] = res_df['item_name'].apply(clean_product_name)
                final_df = res_df.groupby('item_name').sum().reset_index()
                st.subheader(f"ğŸ” ì„ íƒ ìƒí’ˆ í†µí•© ì„±ê³¼")
                st.dataframe(final_df.style.format({'revenue': 'â‚©{:,.0f}'}), use_container_width=True)
        except Exception as e:
            st.error("ìƒí’ˆ ìƒì„¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            st.code(str(e))
