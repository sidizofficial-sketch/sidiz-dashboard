import streamlit as st
import google.generativeai as genai
from google.cloud import bigquery
import pandas as pd
import json
import datetime

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ AI Intelligence", page_icon="ğŸª‘", layout="wide")

# 2. ë³´ì•ˆ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„
try:
    # Secrets ì½ê¸°
    info = json.loads(st.secrets["gcp_service_account"]["json_key"])
    client = bigquery.Client.from_service_account_info(info)
    
    # Gemini API ì„¤ì •
    if "gemini" in st.secrets and "api_key" in st.secrets["gemini"]:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        st.sidebar.success("âœ… Gemini API ì—°ê²° ì¤€ë¹„ ì™„ë£Œ")
    else:
        st.sidebar.error("âŒ Gemini API í‚¤ë¥¼ Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ë‚ ì§œ ìë™ ê³„ì‚°
    today = datetime.date.today().strftime('%Y%m%d')
    three_months_ago = (datetime.date.today() - datetime.timedelta(days=90)).strftime('%Y%m%d')

    # 3. ì œë¯¸ë‚˜ì´ ì§€ì¹¨ ì •ì˜ (í•©ì¹˜ê¸°ìš©)
    INSTRUCTION = f"""
    ë‹¹ì‹ ì€ ì‹œë””ì¦ˆ(SIDIZ)ì˜ ì‹œë‹ˆì–´ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì•„ë˜ ê·œì¹™ì„ ë°”íƒ•ìœ¼ë¡œ SQLì„ ìƒì„±í•˜ê³  ë¶„ì„ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.

    [ë°ì´í„°ì…‹ ì •ë³´]
    - í”„ë¡œì íŠ¸ ID: `{info['project_id']}`
    - ë°ì´í„°ì…‹: `analytics_324424314`
    - í…Œì´ë¸”: `events_*`
    - ì˜¤ëŠ˜ ë‚ ì§œ: {today}

    [SQL ê·œì¹™]
    1. ë‚ ì§œ í•„í„°ë§: ë°˜ë“œì‹œ `_TABLE_SUFFIX BETWEEN '{three_months_ago}' AND '{today}'` í˜•íƒœë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    2. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ SQL ì¿¼ë¦¬ì™€ í•¨ê»˜ í•œê¸€ ë¶„ì„ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.
    """

    # [ì¤‘ìš”] ëª¨ë¸ëª…ì„ í’€ë„¤ì„ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ 404 ì—ëŸ¬ ë°©ì§€
    model = genai.GenerativeModel('models/gemini-1.5-flash')

except Exception as e:
    st.error(f"ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# 4. UI êµ¬ì„±
st.title("ğŸª‘ SIDIZ Data Intelligence Portal")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë°ì´í„°ì—ê²Œ ë§ì„ ê±¸ì–´ë³´ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ë¹…ì¿¼ë¦¬ ë¶„ì„ ì—”ì§„ ê°€ë™ ì¤‘..."):
            try:
                # í•©ì³ì§„ í”„ë¡¬í”„íŠ¸ë¡œ ì „ë‹¬
                combined_prompt = f"{INSTRUCTION}\n\nì‚¬ìš©ì ì§ˆë¬¸: {prompt}"
                response = model.generate_content(combined_prompt)
                
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                # ì—¬ê¸°ì„œë„ ì—ëŸ¬ê°€ ë‚˜ë©´ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•´ë²„ë¦½ë‹ˆë‹¤ (ë””ë²„ê¹…ìš©)
                st.error(f"ëª¨ë¸ ì—°ê²° ì˜¤ë¥˜. ë‹¤ë¥¸ ëª¨ë¸ëª…ì„ ì‹œë„í•´ì•¼ í•©ë‹ˆë‹¤: {e}")
