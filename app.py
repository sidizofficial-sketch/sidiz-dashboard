# SIDIZ Dashboard v2.2 - NameError í•´ê²° ì™„ë£Œ ë²„ì „
import streamlit as st
from google.cloud import bigquery
import pandas as pd
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ Intelligence Dashboard", layout="wide")

@st.cache_resource
def get_bq_client():
    try:
        info = json.loads(st.secrets["gcp_service_account"]["json_key"])
        return bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    except Exception as e:
        st.error(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

client = get_bq_client()

# -------------------------------------------------
# 2. ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ (EASY REPAIR í•„í„°ë§ í¬í•¨)
# -------------------------------------------------
def get_dashboard_data(start_c, end_c, start_p, end_p, time_unit, data_source="ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)"):
    if client is None:
        return None, None
    
    # ë‚ ì§œ ë³€ìˆ˜ ë¯¸ë¦¬ ë³€í™˜ (f-string ì¶©ëŒ ë°©ì§€)
    s_c = start_c.strftime('%Y%m%d')
    e_c = end_c.strftime('%Y%m%d')
    s_p = start_p.strftime('%Y%m%d')
    e_p = end_p.strftime('%Y%m%d')
    
    min_date = min(s_c, s_p)
    max_date = max(e_c, e_p)

    if time_unit == "ì¼ë³„":
        group_sql = "PARSE_DATE('%Y%m%d', event_date)"
    elif time_unit == "ì£¼ë³„":
        group_sql = "DATE_TRUNC(PARSE_DATE('%Y%m%d', event_date), WEEK)"
    else:
        group_sql = "DATE_TRUNC(PARSE_DATE('%Y%m%d', event_date), MONTH)"

    # í•µì‹¬ ì§€í‘œ ì¿¼ë¦¬ (.format() ë°©ì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€ìˆ˜ ì¹˜í™˜)
    if data_source == "ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)":
        # ë§¤ì¥ ë°ì´í„° ì œì™¸ ëª¨ë“œ
        query = """
    WITH store_sessions AS (
        -- ë§¤ì¥ ìœ ì… ì„¸ì…˜ ë¸”ë™ë¦¬ìŠ¤íŠ¸: 11ê°œ ë§¤ì¥ QR ì½”ë“œ
        SELECT DISTINCT 
            CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING)) as session_key
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
        AND (
            -- traffic_source.source
            LOWER(COALESCE(traffic_source.source, '')) IN (
                'store_register_qr',
                'qr_store_',
                'qr_store_247482',
                'qr_store_247483',
                'qr_store_247488',
                'qr_store_247476',
                'qr_store_247474',
                'qr_store_247486',
                'qr_store_247489',
                'qr_store_252941',
                'qr_store_247475'
            ) OR
            -- event_paramsì˜ source
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1), '')) IN (
                'store_register_qr',
                'qr_store_',
                'qr_store_247482',
                'qr_store_247483',
                'qr_store_247488',
                'qr_store_247476',
                'qr_store_247474',
                'qr_store_247486',
                'qr_store_247489',
                'qr_store_252941',
                'qr_store_247475'
            ) OR
            -- collected_traffic_source.manual_source
            LOWER(COALESCE(collected_traffic_source.manual_source, '')) IN (
                'store_register_qr',
                'qr_store_',
                'qr_store_247482',
                'qr_store_247483',
                'qr_store_247488',
                'qr_store_247476',
                'qr_store_247474',
                'qr_store_247486',
                'qr_store_247489',
                'qr_store_252941',
                'qr_store_247475'
            )
        )
    ),
    base AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id, event_name, ecommerce.purchase_revenue, ecommerce.transaction_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num,
            items
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
    ),
    filtered_base AS (
        -- ë§¤ì¥ ì„¸ì…˜ ì œì™¸ (session_key ê¸°ë°˜)
        SELECT b.*
        FROM base b
        WHERE CONCAT(b.user_pseudo_id, CAST(b.sid AS STRING)) NOT IN (
            SELECT session_key FROM store_sessions
        )
    ),
    easy_repair_only_orders AS (
        SELECT transaction_id
        FROM filtered_base, UNNEST(items) as item
        WHERE event_name = 'purchase'
        GROUP BY transaction_id
        HAVING LOGICAL_AND(
            REGEXP_CONTAINS(UPPER(IFNULL(item.item_category, '')), r'EASY.REPAIR') OR 
            REGEXP_CONTAINS(UPPER(IFNULL(item.item_name, '')), r'EASY.REPAIR') OR
            REGEXP_CONTAINS(item.item_name, r'íŒ¨ë“œ|í—¤ë“œë ˆìŠ¤íŠ¸|ì»¤ë²„|ë‹¤ë¦¬|ë°”í€´|ê¸€ë¼ì´ë“œ|ë¸”ë¡|ì¢ŒíŒ|ì´ì§€ë¦¬í˜ì–´')
        )
    )
    SELECT 
        CASE WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}') THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(sid AS STRING))) as sessions,
        COUNTIF(event_name = 'sign_up') as signups,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue,
        COUNTIF(event_name = 'purchase' AND transaction_id NOT IN (SELECT transaction_id FROM easy_repair_only_orders)) as filtered_orders,
        SUM(CASE WHEN event_name = 'purchase' AND transaction_id NOT IN (SELECT transaction_id FROM easy_repair_only_orders) THEN purchase_revenue ELSE 0 END) as filtered_revenue
    FROM filtered_base
    GROUP BY 1 
    HAVING type IS NOT NULL
    """.format(min_date=min_date, max_date=max_date, s_c=s_c, e_c=e_c)
    
Python
    elif data_source == "ë§¤ì¥ ì „ìš©":
        # 1. ë©”ì¸ ì§€í‘œìš© ì¿¼ë¦¬ (15,765,000ì› ì •ë°€ íƒ€ê²©)
        query = """
    WITH raw_events AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id,
            event_name,
            ecommerce.purchase_revenue,
            ecommerce.transaction_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num,
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1), traffic_source.source, '')) as src,
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium' LIMIT 1), traffic_source.medium, '')) as med
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
    ),
    filtered_events AS (
        SELECT *, CONCAT(user_pseudo_id, CAST(sid AS STRING)) as session_key
        FROM raw_events
        WHERE src IN ('store_register_qr', 'qr_store_', 'qr_store_247482', 'qr_store_247483', 'qr_store_247488', 'qr_store_247476', 'qr_store_247474', 'qr_store_247486', 'qr_store_247489', 'qr_store_252941', 'qr_store_247475')
          AND med IN ('qr_code', 'qr_coupon', 'qr_product')
    )
    SELECT 
        CASE WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}') THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT session_key) as sessions,
        COUNTIF(event_name = 'sign_up') as signups,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue,
        SUM(IFNULL(purchase_revenue, 0)) as filtered_revenue
    FROM filtered_events
    GROUP BY 1 HAVING type IS NOT NULL
    """.format(min_date=min_date, max_date=max_date, s_c=s_c, e_c=e_c)

        # 2. ì‹œê³„ì—´ ê·¸ë˜í”„ìš© ì¿¼ë¦¬ (NameError í•´ê²°)
        ts_query = """
    WITH raw_ts AS (
        SELECT 
            {group_sql} as period_date,
            user_pseudo_id,
            event_name,
            ecommerce.purchase_revenue,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1), traffic_source.source, '')) as src,
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium' LIMIT 1), traffic_source.medium, '')) as med
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
    )
    SELECT 
        CAST(period_date AS STRING) as period_label,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(sid AS STRING))) as sessions,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase') as orders
    FROM raw_ts
    WHERE src IN ('store_register_qr', 'qr_store_', 'qr_store_247482', 'qr_store_247483', 'qr_store_247488', 'qr_store_247476', 'qr_store_247474', 'qr_store_247486', 'qr_store_247489', 'qr_store_252941', 'qr_store_247475')
      AND med IN ('qr_code', 'qr_coupon', 'qr_product')
    GROUP BY 1 ORDER BY 1
    """.format(s_c=s_c, e_c=e_c, group_sql=group_sql)
    
    else:
        # ì „ì²´ ë°ì´í„° ëª¨ë“œ
        query = """
    WITH base AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id, event_name, ecommerce.purchase_revenue, ecommerce.transaction_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num,
            items
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
    ),
    easy_repair_only_orders AS (
        SELECT transaction_id
        FROM base, UNNEST(items) as item
        WHERE event_name = 'purchase'
        GROUP BY transaction_id
        HAVING LOGICAL_AND(
            REGEXP_CONTAINS(UPPER(IFNULL(item.item_category, '')), r'EASY.REPAIR') OR 
            REGEXP_CONTAINS(UPPER(IFNULL(item.item_name, '')), r'EASY.REPAIR') OR
            REGEXP_CONTAINS(item.item_name, r'íŒ¨ë“œ|í—¤ë“œë ˆìŠ¤íŠ¸|ì»¤ë²„|ë‹¤ë¦¬|ë°”í€´|ê¸€ë¼ì´ë“œ|ë¸”ë¡|ì¢ŒíŒ|ì´ì§€ë¦¬í˜ì–´')
        )
    )
    SELECT 
        CASE WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}') THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(sid AS STRING))) as sessions,
        COUNTIF(event_name = 'sign_up') as signups,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue,
        COUNTIF(event_name = 'purchase' AND transaction_id NOT IN (SELECT transaction_id FROM easy_repair_only_orders)) as filtered_orders,
        SUM(CASE WHEN event_name = 'purchase' AND transaction_id NOT IN (SELECT transaction_id FROM easy_repair_only_orders) THEN purchase_revenue ELSE 0 END) as filtered_revenue
    FROM base
    GROUP BY 1 
    HAVING type IS NOT NULL
    """.format(min_date=min_date, max_date=max_date, s_c=s_c, e_c=e_c)

    # ì‹œê³„ì—´ ë°ì´í„°
    if data_source == "ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)":
        ts_query = """
        WITH store_sessions AS (
            -- ë§¤ì¥ ìœ ì… ì„¸ì…˜ ë¸”ë™ë¦¬ìŠ¤íŠ¸: store í¬í•¨ ëª¨ë“  ì†ŒìŠ¤
            SELECT DISTINCT 
                CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING)) as session_key
            FROM `sidiz-458301.analytics_487246344.events_*`
            WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
            AND (
                -- traffic_sourceì—ì„œ 'store' í¬í•¨
                LOWER(COALESCE(traffic_source.source, '')) LIKE '%store%' OR
                LOWER(COALESCE(traffic_source.medium, '')) LIKE '%store%' OR
                -- event_paramsì—ì„œ 'store' í¬í•¨
                LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1), '')) LIKE '%store%' OR
                LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium' LIMIT 1), '')) LIKE '%store%' OR
                -- collected_traffic_sourceì—ì„œ 'store' í¬í•¨
                LOWER(COALESCE(collected_traffic_source.manual_source, '')) LIKE '%store%' OR
                LOWER(COALESCE(collected_traffic_source.manual_medium, '')) LIKE '%store%'
            )
        ),
        events_base AS (
            SELECT 
                {group_sql} as period_date,
                user_pseudo_id,
                (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
                event_name,
                ecommerce.purchase_revenue
            FROM `sidiz-458301.analytics_487246344.events_*`
            WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        )
        SELECT 
            CAST(period_date AS STRING) as period_label,
            COUNT(DISTINCT CONCAT(e.user_pseudo_id, CAST(e.sid AS STRING))) as sessions,
            SUM(IFNULL(e.purchase_revenue, 0)) as revenue,
            COUNTIF(e.event_name = 'purchase') as orders
        FROM events_base e
        WHERE CONCAT(e.user_pseudo_id, CAST(e.sid AS STRING)) NOT IN (
            SELECT session_key FROM store_sessions
        )
        GROUP BY 1 ORDER BY 1
        """.format(s_c=s_c, e_c=e_c, group_sql=group_sql)
    
    elif data_source == "ë§¤ì¥ ì „ìš©":
        query = """
    WITH raw_events AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id,
            event_name,
            ecommerce.purchase_revenue,
            ecommerce.transaction_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num,
            -- ì†ŒìŠ¤ì™€ ë§¤ì²´ë¥¼ ì¶”ì¶œ (LOWERë¡œ í†µì¼)
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1), traffic_source.source, '')) as src,
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium' LIMIT 1), traffic_source.medium, '')) as med
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
    ),
    filtered_events AS (
        SELECT *,
            CONCAT(user_pseudo_id, CAST(sid AS STRING)) as session_key
        FROM raw_events
        WHERE 
            -- 1. ì†ŒìŠ¤ 11ê°œ ê³ ì •
            src IN (
                'store_register_qr', 'qr_store_', 'qr_store_247482', 'qr_store_247483', 
                'qr_store_247488', 'qr_store_247476', 'qr_store_247474', 'qr_store_247486', 
                'qr_store_247489', 'qr_store_252941', 'qr_store_247475'
            )
            -- 2. ë§¤ì²´ 3ê°œ ê³ ì • (ì´ë¯¸ì§€ì—ì„œ í™•ì¸ëœ ê°’)
            AND med IN ('qr_code', 'qr_coupon', 'qr_product')
    )
    SELECT 
        CASE WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}') THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT session_key) as sessions,
        COUNTIF(event_name = 'sign_up') as signups,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        -- ëŒ€ëŸ‰êµ¬ë§¤ ë° í•„í„°ë§ ë§¤ì¶œ ì§‘ê³„
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue,
        SUM(IFNULL(purchase_revenue, 0)) as filtered_revenue
    FROM filtered_events
    GROUP BY 1 
    HAVING type IS NOT NULL
    """.format(min_date=min_date, max_date=max_date, s_c=s_c, e_c=e_c)
    
    else:
        ts_query = f"""
        SELECT 
            CAST({group_sql} AS STRING) as period_label, 
            COUNT(DISTINCT CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING))) as sessions,
            SUM(IFNULL(ecommerce.purchase_revenue, 0)) as revenue,
            COUNTIF(event_name = 'purchase') as orders
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        GROUP BY 1 ORDER BY 1
        """
    try:
        return client.query(query).to_dataframe(), client.query(ts_query).to_dataframe()
    except Exception as e:
        st.error(f"âš ï¸ ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None

# -------------------------------------------------
# 3. ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì¶”ì¶œ (TOP3 + ì¦ê°ìœ¨)
# -------------------------------------------------
def get_insight_data(start_c, end_c, start_p, end_p, data_source="ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)"):
    if client is None:
        return None
    
    # ë‚ ì§œ ë³€ìˆ˜ ë¯¸ë¦¬ ë³€í™˜ (f-string ì¶©ëŒ ë°©ì§€)
    s_c = start_c.strftime('%Y%m%d')
    e_c = end_c.strftime('%Y%m%d')
    s_p = start_p.strftime('%Y%m%d')
    e_p = end_p.strftime('%Y%m%d')
    
    min_date = min(s_c, s_p)
    max_date = max(e_c, e_p)

    # ì œí’ˆë³„ ë§¤ì¶œ ë³€í™” (item_id ê¸°ì¤€)
    if data_source == "ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)":
        product_query = """
        WITH store_sessions AS (
        -- ë§¤ì¥ ìœ ì… ì„¸ì…˜ ë¸”ë™ë¦¬ìŠ¤íŠ¸: store í¬í•¨ ëª¨ë“  ì†ŒìŠ¤
        SELECT DISTINCT 
            CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING)) as session_key
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
        AND (
            -- traffic_sourceì—ì„œ 'store' í¬í•¨
            LOWER(COALESCE(traffic_source.source, '')) LIKE '%store%' OR
            LOWER(COALESCE(traffic_source.medium, '')) LIKE '%store%' OR
            -- event_paramsì—ì„œ 'store' í¬í•¨
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1), '')) LIKE '%store%' OR
            LOWER(COALESCE((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium' LIMIT 1), '')) LIKE '%store%' OR
            -- collected_traffic_sourceì—ì„œ 'store' í¬í•¨
            LOWER(COALESCE(collected_traffic_source.manual_source, '')) LIKE '%store%' OR
            LOWER(COALESCE(collected_traffic_source.manual_medium, '')) LIKE '%store%'
        )
    ),
    base AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id,
            event_name,
            ecommerce.purchase_revenue,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            items
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
    ),
    filtered_base AS (
        -- ë§¤ì¥ ì„¸ì…˜ ì œì™¸ (session_key ê¸°ë°˜)
        SELECT b.*
        FROM base b
        WHERE CONCAT(b.user_pseudo_id, CAST(b.sid AS STRING)) NOT IN (
            SELECT session_key FROM store_sessions
        )
    ),
        """
    else:
        product_query = """
        WITH base AS (
            SELECT 
                PARSE_DATE('%Y%m%d', event_date) as date,
                user_pseudo_id,
                event_name,
                ecommerce.purchase_revenue,
                (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
                items
            FROM `sidiz-458301.analytics_487246344.events_*`
            WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
        ),
        """
    
    product_query += """
    product_items AS (
        SELECT 
            date,
            user_pseudo_id,
            event_name,
            sid,
            -- item_id ê¸°ì¤€ (ì—†ìœ¼ë©´ ì •ê·œí™”ëœ ì´ë¦„)
            COALESCE(
                item.item_id,
                REGEXP_REPLACE(
                    UPPER(TRIM(REGEXP_REPLACE(item.item_name, r'\\[.*?\\]', ''))),
                    r'\\s+|[^A-Z0-9ê°€-í£]', ''
                )
            ) as match_key,
            item.item_name as original_name,
            item.price,
            item.quantity
        FROM """ + ("filtered_base" if exclude_store else "base") + """, UNNEST(items) as item
        WHERE item.item_name IS NOT NULL
    ),
    latest_product_names AS (
        SELECT 
            match_key,
            ARRAY_AGG(original_name ORDER BY date DESC LIMIT 1)[OFFSET(0)] as product_name
        FROM product_items
        GROUP BY match_key
    ),
    product_metrics AS (
        SELECT 
            match_key,
            -- í˜„ì¬ ê¸°ê°„ ë§¤ì¶œ (í•µì‹¬ ì„±ê³¼ ìš”ì•½ê³¼ ë™ì¼)
            SUM(CASE 
                WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}')
                AND event_name = 'purchase'
                THEN COALESCE(price, 0) * COALESCE(quantity, 0)
                ELSE 0
            END) as curr_rev,
            
            -- ì´ì „ ê¸°ê°„ ë§¤ì¶œ
            SUM(CASE 
                WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_p}') AND PARSE_DATE('%Y%m%d', '{e_p}')
                AND event_name = 'purchase'
                THEN COALESCE(price, 0) * COALESCE(quantity, 0)
                ELSE 0
            END) as prev_rev,
            
            -- ì„¸ì…˜ (í•µì‹¬ ì„±ê³¼ ìš”ì•½ê³¼ ë™ì¼)
            COUNT(DISTINCT CASE 
                WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}')
                THEN CONCAT(user_pseudo_id, CAST(sid AS STRING))
            END) as curr_sess,
            
            COUNT(DISTINCT CASE 
                WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_p}') AND PARSE_DATE('%Y%m%d', '{e_p}')
                THEN CONCAT(user_pseudo_id, CAST(sid AS STRING))
            END) as prev_sess,
            
            -- ìˆ˜ëŸ‰
            SUM(CASE 
                WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}')
                AND event_name = 'purchase'
                THEN COALESCE(quantity, 0)
                ELSE 0
            END) as curr_qty,
            
            SUM(CASE 
                WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_p}') AND PARSE_DATE('%Y%m%d', '{e_p}')
                AND event_name = 'purchase'
                THEN COALESCE(quantity, 0)
                ELSE 0
            END) as prev_qty
        FROM product_items
        GROUP BY match_key
    )
    SELECT 
        n.product_name,
        m.curr_rev as current_revenue,
        m.prev_rev as previous_revenue,
        m.curr_rev - m.prev_rev as revenue_change,
        ROUND(SAFE_DIVIDE((m.curr_rev - m.prev_rev) * 100, NULLIF(m.prev_rev, 0)), 1) as change_pct,
        m.curr_sess as current_sessions,
        m.prev_sess as previous_sessions,
        m.curr_qty as current_quantity,
        m.prev_qty as previous_quantity
    FROM product_metrics m
    JOIN latest_product_names n ON m.match_key = n.match_key
    WHERE m.curr_rev > 0 OR m.prev_rev > 0
    ORDER BY m.curr_rev DESC
    LIMIT 20
    """.format(min_date=min_date, max_date=max_date, s_c=s_c, e_c=e_c, s_p=s_p, e_p=e_p)

    # ì±„ë„ë³„ ë§¤ì¶œ & ì„¸ì…˜ ë³€í™” (í†µí•© ì¿¼ë¦¬ - ë‹¨ì¼ ì†ŒìŠ¤)
    channel_combined_query = """
    WITH base_events AS (
        SELECT 
            user_pseudo_id,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as session_id,
            event_name,
            ecommerce.purchase_revenue,
            -- ì´ë²¤íŠ¸ íŒŒë¼ë¯¸í„°ì—ì„œë§Œ ì†ŒìŠ¤/ë§¤ì²´ ì¶”ì¶œ (traffic_source ì‚¬ìš© ì¤‘ë‹¨)
            LOWER(NULLIF(TRIM((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source' LIMIT 1)), '')) as raw_source,
            LOWER(NULLIF(TRIM((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium' LIMIT 1)), '')) as raw_medium,
            event_timestamp,
            _TABLE_SUFFIX as suffix
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
        
    ),
    session_mapping AS (
        SELECT 
            user_pseudo_id,
            session_id,
            suffix,
            event_name,
            purchase_revenue,
            -- ì„¸ì…˜ ë‚´ì—ì„œ NULLì´ ì•„ë‹Œ ì²« ë²ˆì§¸ ì†ŒìŠ¤ ê°’ì„ ì°¾ì•„ ì „íŒŒ (IGNORE NULLS)
            COALESCE(
                FIRST_VALUE(raw_source IGNORE NULLS) OVER (
                    PARTITION BY user_pseudo_id, session_id 
                    ORDER BY event_timestamp 
                    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
                ),
                '(direct)'
            ) as final_source,
            COALESCE(
                FIRST_VALUE(raw_medium IGNORE NULLS) OVER (
                    PARTITION BY user_pseudo_id, session_id 
                    ORDER BY event_timestamp 
                    ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
                ),
                '(none)'
            ) as final_medium
        FROM base_events
    ),
    events_with_channel AS (
        SELECT 
            suffix,
            CONCAT(final_source, ' / ', final_medium) as channel,
            CONCAT(user_pseudo_id, '-', CAST(session_id AS STRING)) as unique_session,
            event_name,
            purchase_revenue
        FROM session_mapping
    ),
    aggregated AS (
        SELECT 
            channel,
            -- í˜„ì¬ ê¸°ê°„ ë§¤ì¶œ
            SUM(CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' AND event_name = 'purchase' THEN COALESCE(purchase_revenue, 0) ELSE 0 END) as current_revenue,
            -- ì´ì „ ê¸°ê°„ ë§¤ì¶œ
            SUM(CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' AND event_name = 'purchase' THEN COALESCE(purchase_revenue, 0) ELSE 0 END) as previous_revenue,
            -- í˜„ì¬ ê¸°ê°„ ì„¸ì…˜
            COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN unique_session END) as current_sessions,
            -- ì´ì „ ê¸°ê°„ ì„¸ì…˜
            COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN unique_session END) as previous_sessions
        FROM events_with_channel
        GROUP BY 1
    )
    SELECT 
        channel as channel_name,
        COALESCE(current_revenue, 0) as current_revenue,
        COALESCE(previous_revenue, 0) as previous_revenue,
        COALESCE(current_revenue, 0) - COALESCE(previous_revenue, 0) as revenue_change,
        ROUND(SAFE_DIVIDE((COALESCE(current_revenue, 0) - COALESCE(previous_revenue, 0)) * 100, NULLIF(COALESCE(previous_revenue, 0), 0)), 1) as revenue_change_pct,
        COALESCE(current_sessions, 0) as current_sessions,
        COALESCE(previous_sessions, 0) as previous_sessions,
        COALESCE(current_sessions, 0) - COALESCE(previous_sessions, 0) as sessions_change,
        ROUND(SAFE_DIVIDE((COALESCE(current_sessions, 0) - COALESCE(previous_sessions, 0)) * 100, NULLIF(COALESCE(previous_sessions, 0), 0)), 1) as sessions_change_pct
    FROM aggregated
    ORDER BY COALESCE(current_revenue, 0) DESC
    LIMIT 20
    """
    # ì§€ì—­ë³„ ë³€í™”
    demo_query = """
    WITH current_demo AS (
        SELECT CONCAT(IFNULL(geo.country, 'Unknown'), ' / ', IFNULL(geo.city, 'Unknown')) as location, SUM(ecommerce.purchase_revenue) as revenue 
        FROM `sidiz-458301.analytics_487246344.events_*` 
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}' AND event_name = 'purchase' 
        GROUP BY 1
    ),
    previous_demo AS (
        SELECT CONCAT(IFNULL(geo.country, 'Unknown'), ' / ', IFNULL(geo.city, 'Unknown')) as location, SUM(ecommerce.purchase_revenue) as revenue 
        FROM `sidiz-458301.analytics_487246344.events_*` 
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}' AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.location, p.location), 
        IFNULL(c.revenue, 0), 
        IFNULL(p.revenue, 0), 
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0), 
        ROUND(SAFE_DIVIDE((IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) * 100, IFNULL(p.revenue, 0)), 1)
    FROM current_demo c 
    FULL OUTER JOIN previous_demo p ON c.location = p.location 
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC 
    LIMIT 10
    """.format(s_c=s_c, e_c=e_c, s_p=s_p, e_p=e_p)

    # ë””ë°”ì´ìŠ¤ë³„ ë³€í™”
    device_query = """
    WITH current_device AS (
        SELECT device.category as device, SUM(ecommerce.purchase_revenue) as revenue 
        FROM `sidiz-458301.analytics_487246344.events_*` 
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}' AND event_name = 'purchase' 
        GROUP BY 1
    ),
    previous_device AS (
        SELECT device.category as device, SUM(ecommerce.purchase_revenue) as revenue 
        FROM `sidiz-458301.analytics_487246344.events_*` 
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}' AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.device, p.device), 
        IFNULL(c.revenue, 0), 
        IFNULL(p.revenue, 0), 
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0), 
        ROUND(SAFE_DIVIDE((IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) * 100, IFNULL(p.revenue, 0)), 1)
    FROM current_device c 
    FULL OUTER JOIN previous_device p ON c.device = p.device 
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    """.format(s_c=s_c, e_c=e_c, s_p=s_p, e_p=e_p)

    # ì¸êµ¬í†µê³„ë³„ ë§¤ì¶œ & ì„¸ì…˜ ë³€í™” (user_properties í¬í•¨ + í•„í„° ì œê±°)
    demographics_combined_query = """
    WITH base_events AS (
        SELECT 
            _TABLE_SUFFIX as suffix,
            user_pseudo_id,
            event_name,
            ecommerce.purchase_revenue,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as session_id,
            -- event_paramsì—ì„œ ì„±ë³„ ì¶”ì¶œ (ì—¬ëŸ¬ í‚¤ ì‹œë„)
            COALESCE(
                LOWER((SELECT value.string_value FROM UNNEST(event_params) WHERE key IN ('u_gender', 'gender', 'sex', 'user_gender') LIMIT 1)),
                LOWER((SELECT value.string_value FROM UNNEST(user_properties) WHERE key IN ('u_gender', 'gender', 'sex', 'user_gender') LIMIT 1)),
                ''
            ) as gender_raw,
            -- event_paramsì—ì„œ ì—°ë ¹ ì¶”ì¶œ (ì—¬ëŸ¬ í‚¤ ì‹œë„)
            COALESCE(
                (SELECT value.string_value FROM UNNEST(event_params) WHERE key IN ('u_age', 'age', 'age_group', 'user_age') LIMIT 1),
                (SELECT value.string_value FROM UNNEST(user_properties) WHERE key IN ('u_age', 'age', 'age_group', 'user_age') LIMIT 1),
                'ë¯¸ë¶„ë¥˜'
            ) as age_raw
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min_date}' AND '{max_date}'
        
    ),
    normalized_demographics AS (
        SELECT 
            suffix,
            user_pseudo_id,
            session_id,
            event_name,
            purchase_revenue,
            CASE 
                WHEN gender_raw IN ('male', 'm', 'ë‚¨ì„±', '1') THEN 'ë‚¨ì„±'
                WHEN gender_raw IN ('female', 'f', 'ì—¬ì„±', '2') THEN 'ì—¬ì„±'
                ELSE 'ë¯¸ë¶„ë¥˜'
            END as gender_normalized,
            COALESCE(NULLIF(age_raw, ''), 'ë¯¸ë¶„ë¥˜') as age_normalized
        FROM base_events
    ),
    aggregated AS (
        SELECT 
            CONCAT(
                COALESCE(gender_normalized, 'ë¯¸ë¶„ë¥˜'), 
                ' / ', 
                COALESCE(age_normalized, 'ë¯¸ë¶„ë¥˜')
            ) as demographic,
            -- í˜„ì¬ ê¸°ê°„ ë§¤ì¶œ
            SUM(CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' AND event_name = 'purchase' THEN IFNULL(purchase_revenue, 0) ELSE 0 END) as current_revenue,
            -- ì´ì „ ê¸°ê°„ ë§¤ì¶œ
            SUM(CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' AND event_name = 'purchase' THEN IFNULL(purchase_revenue, 0) ELSE 0 END) as previous_revenue,
            -- í˜„ì¬ ê¸°ê°„ ì„¸ì…˜
            COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_c}' AND '{e_c}' THEN CONCAT(user_pseudo_id, '-', CAST(session_id AS STRING)) END) as current_sessions,
            -- ì´ì „ ê¸°ê°„ ì„¸ì…˜
            COUNT(DISTINCT CASE WHEN suffix BETWEEN '{s_p}' AND '{e_p}' THEN CONCAT(user_pseudo_id, '-', CAST(session_id AS STRING)) END) as previous_sessions
        FROM normalized_demographics
        GROUP BY 1
    )
    SELECT 
        COALESCE(demographic, 'ë¯¸ë¶„ë¥˜ / ë¯¸ë¶„ë¥˜') as demographic,
        IFNULL(current_revenue, 0) as current_revenue,
        IFNULL(previous_revenue, 0) as previous_revenue,
        IFNULL(current_revenue - previous_revenue, 0) as revenue_change,
        ROUND(SAFE_DIVIDE((current_revenue - previous_revenue) * 100, NULLIF(previous_revenue, 0)), 1) as revenue_change_pct,
        IFNULL(current_sessions, 0) as current_sessions,
        IFNULL(previous_sessions, 0) as previous_sessions,
        IFNULL(current_sessions - previous_sessions, 0) as sessions_change,
        ROUND(SAFE_DIVIDE((current_sessions - previous_sessions) * 100, NULLIF(previous_sessions, 0)), 1) as sessions_change_pct
    FROM aggregated
    ORDER BY ABS(IFNULL(revenue_change, 0)) DESC
    LIMIT 10
    """.format(min_date=min_date, max_date=max_date, s_c=s_c, e_c=e_c, s_p=s_p, e_p=e_p)

    try:
        # ì¿¼ë¦¬ ì‹¤í–‰
        results = {
            'product': client.query(product_query).to_dataframe(),
            'channel_combined': client.query(channel_combined_query).to_dataframe(),
            'demo': client.query(demo_query).to_dataframe(),
            'device': client.query(device_query).to_dataframe(),
            'demographics_combined': client.query(demographics_combined_query).to_dataframe()
        }
        
        # NaNì„ 0ìœ¼ë¡œ ëª…ì‹œì  ë³€í™˜
        for key in results:
            if results[key] is not None and not results[key].empty:
                numeric_cols = results[key].select_dtypes(include=['float64', 'int64']).columns
                results[key][numeric_cols] = results[key][numeric_cols].fillna(0)
        
        # ì»¬ëŸ¼ëª… ì •í™•íˆ ë§¤ì¹­
        results['product'].columns = ['ì œí’ˆëª…', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'í˜„ì¬ìˆ˜ëŸ‰', 'ì´ì „ìˆ˜ëŸ‰']
        
        # SQLì—ì„œ ì´ë¯¸ ì •ê·œí™” ë° ê·¸ë£¹í™” ì™„ë£Œ - ì¶”ê°€ ì²˜ë¦¬ë§Œ ìˆ˜í–‰
        if 'product' in results and not results['product'].empty:
            pdf = results['product']
            
            # ë³€í™”ëŸ‰ ê³„ì‚°
            pdf['ì„¸ì…˜ë³€í™”'] = pdf['í˜„ì¬ì„¸ì…˜'] - pdf['ì´ì „ì„¸ì…˜']
            pdf['ìˆ˜ëŸ‰ë³€í™”'] = pdf['í˜„ì¬ìˆ˜ëŸ‰'] - pdf['ì´ì „ìˆ˜ëŸ‰']
            
            # ë§¤ì¶œ ë¹„ì¤‘ ê³„ì‚°
            total_revenue = pdf['í˜„ì¬ë§¤ì¶œ'].sum()
            pdf['ë§¤ì¶œë¹„ì¤‘'] = (pdf['í˜„ì¬ë§¤ì¶œ'] / total_revenue * 100 if total_revenue > 0 else 0).round(1)
            
            # ë§¤ì¶œ ë†’ì€ ìˆœ ì •ë ¬
            pdf = pdf.sort_values(by='í˜„ì¬ë§¤ì¶œ', ascending=False).reset_index(drop=True)
            
            results['product'] = pdf
        
        results['channel_combined'].columns = ['ì±„ë„', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ë§¤ì¶œì¦ê°ìœ¨', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì„¸ì…˜ì¦ê°ìœ¨']
        # ì±„ë„ë³„ ë§¤ì¶œ ë†’ì€ ìˆœ ì •ë ¬
        if 'channel_combined' in results and not results['channel_combined'].empty:
            results['channel_combined'] = results['channel_combined'].sort_values(by='í˜„ì¬ë§¤ì¶œ', ascending=False).reset_index(drop=True)
        
        results['demo'].columns = ['ì§€ì—­', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        # ì§€ì—­ë³„ ë§¤ì¶œ ë†’ì€ ìˆœ ì •ë ¬
        if 'demo' in results and not results['demo'].empty:
            results['demo'] = results['demo'].sort_values(by='í˜„ì¬ë§¤ì¶œ', ascending=False).reset_index(drop=True)
        
        results['device'].columns = ['ë””ë°”ì´ìŠ¤', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
        # ë””ë°”ì´ìŠ¤ë³„ ë§¤ì¶œ ë†’ì€ ìˆœ ì •ë ¬
        if 'device' in results and not results['device'].empty:
            results['device'] = results['device'].sort_values(by='í˜„ì¬ë§¤ì¶œ', ascending=False).reset_index(drop=True)
        
        results['demographics_combined'].columns = ['ì¸êµ¬í†µê³„', 'í˜„ì¬ë§¤ì¶œ', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ë§¤ì¶œì¦ê°ìœ¨', 'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì„¸ì…˜ì¦ê°ìœ¨']
        # ì¸êµ¬í†µê³„ë³„ ë§¤ì¶œ ë†’ì€ ìˆœ ì •ë ¬
        if 'demographics_combined' in results and not results['demographics_combined'].empty:
            results['demographics_combined'] = results['demographics_combined'].sort_values(by='í˜„ì¬ë§¤ì¶œ', ascending=False).reset_index(drop=True)
        
        return results
    except Exception as e:
        st.sidebar.error(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
        st.error(f"âš ï¸ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì˜¤ë¥˜: {e}")
        import traceback
        st.sidebar.code(traceback.format_exc())
        return None

# -------------------------------------------------
# 4. ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
# -------------------------------------------------
def generate_insights(curr, prev, insight_data):
    insights = []
    
    # insight_data ìœ íš¨ì„± ê²€ì‚¬
    if not insight_data:
        return "ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    # 1. ì „ì²´ ë§¤ì¶œ ë³€ë™
    rev_change = curr['revenue'] - prev['revenue']
    rev_pct = (rev_change / prev['revenue'] * 100) if prev['revenue'] > 0 else 0
    
    if abs(rev_pct) > 3:
        direction = "ì¦ê°€" if rev_change > 0 else "ê°ì†Œ"
        insights.append(f"### ğŸ“Š ì „ì²´ ë§¤ì¶œ {direction}")
        insights.append(f"ë§¤ì¶œì´ **â‚©{abs(rev_change):,.0f} ({abs(rev_pct):.1f}%) {direction}**í–ˆìŠµë‹ˆë‹¤.")
    
    # 2. ì œí’ˆ ì˜í–¥ (TOP3)
    if 'product' in insight_data and insight_data['product'] is not None and not insight_data['product'].empty:
        insights.append(f"\n### ğŸ† ì£¼ìš” ì œí’ˆ ì˜í–¥ TOP3")
        for idx, row in insight_data['product'].head(3).iterrows():
            if abs(row['ë§¤ì¶œë³€í™”']) > 500000:
                direction = "â†‘" if row['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì œí’ˆëª…']}** {direction} â‚©{abs(row['ë§¤ì¶œë³€í™”']):,.0f} ({row['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 3. ì±„ë„ ë§¤ì¶œ ì˜í–¥ (TOP3)
    if 'channel_combined' in insight_data and insight_data['channel_combined'] is not None and not insight_data['channel_combined'].empty:
        insights.append(f"\n### ğŸ¯ ì£¼ìš” ì±„ë„ ë§¤ì¶œ ì˜í–¥ TOP3")
        for idx, row in insight_data['channel_combined'].head(3).iterrows():
            if abs(row['ë§¤ì¶œë³€í™”']) > 300000:
                direction = "â†‘" if row['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì±„ë„']}** {direction} â‚©{abs(row['ë§¤ì¶œë³€í™”']):,.0f} ({row['ë§¤ì¶œì¦ê°ìœ¨']:+.1f}%)")
    
    # 4. ì±„ë„ ìœ ì… ì˜í–¥ (TOP3)
    if 'channel_combined' in insight_data and insight_data['channel_combined'] is not None and not insight_data['channel_combined'].empty:
        insights.append(f"\n### ğŸšª ì£¼ìš” ì±„ë„ ìœ ì… ì˜í–¥ TOP3")
        # ì„¸ì…˜ ë³€í™”ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        channel_sessions_top3 = insight_data['channel_combined'].sort_values('ì„¸ì…˜ë³€í™”', ascending=False, key=abs).head(3)
        for idx, (i, row) in enumerate(channel_sessions_top3.iterrows()):
            if abs(row['ì„¸ì…˜ë³€í™”']) > 100:
                direction = "â†‘" if row['ì„¸ì…˜ë³€í™”'] > 0 else "â†“"
                insights.append(f"**{idx+1}. {row['ì±„ë„']}** {direction} {abs(row['ì„¸ì…˜ë³€í™”']):,.0f}ì„¸ì…˜ ({row['ì„¸ì…˜ì¦ê°ìœ¨']:+.1f}%)")
    
    # 5. ì¸êµ¬í†µê³„ ë§¤ì¶œ ì˜í–¥ (TOP3) - ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬
    if 'demographics_combined' in insight_data and insight_data['demographics_combined'] is not None and not insight_data['demographics_combined'].empty:
        try:
            # 'ë¯¸ë¶„ë¥˜ / ë¯¸ë¶„ë¥˜'ê°€ ì•„ë‹Œ ë°ì´í„°ë§Œ í•„í„°ë§
            demo_df = insight_data['demographics_combined']
            demo_df_filtered = demo_df[~demo_df['ì¸êµ¬í†µê³„'].str.contains('ë¯¸ë¶„ë¥˜', na=False)]
            
            if not demo_df_filtered.empty and len(demo_df_filtered) > 0:
                insights.append(f"\n### ğŸ‘¥ ì¸êµ¬í†µê³„ ë§¤ì¶œ ì˜í–¥ TOP3")
                for idx, row in demo_df_filtered.head(3).iterrows():
                    if abs(row['ë§¤ì¶œë³€í™”']) > 300000:
                        direction = "â†‘" if row['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
                        insights.append(f"**{idx+1}. {row['ì¸êµ¬í†µê³„']}** {direction} â‚©{abs(row['ë§¤ì¶œë³€í™”']):,.0f} ({row['ë§¤ì¶œì¦ê°ìœ¨']:+.1f}%)")
        except Exception as e:
            pass  # ì¸êµ¬í†µê³„ ë°ì´í„° ì˜¤ë¥˜ ì‹œ ì¡°ìš©íˆ ìŠ¤í‚µ
    
    # 6. ì¸êµ¬í†µê³„ ìœ ì… ì˜í–¥ (TOP3) - ê°•í™”ëœ ì˜ˆì™¸ ì²˜ë¦¬
    if 'demographics_combined' in insight_data and insight_data['demographics_combined'] is not None and not insight_data['demographics_combined'].empty:
        try:
            demo_df = insight_data['demographics_combined']
            demo_df_filtered = demo_df[~demo_df['ì¸êµ¬í†µê³„'].str.contains('ë¯¸ë¶„ë¥˜', na=False)]
            
            if not demo_df_filtered.empty and len(demo_df_filtered) > 0:
                demo_ses_top3 = demo_df_filtered.sort_values('ì„¸ì…˜ë³€í™”', ascending=False, key=abs).head(3)
                if not demo_ses_top3.empty:
                    insights.append(f"\n### ğŸš¶ ì¸êµ¬í†µê³„ ìœ ì… ì˜í–¥ TOP3")
                    for idx, (i, row) in enumerate(demo_ses_top3.iterrows()):
                        if abs(row['ì„¸ì…˜ë³€í™”']) > 100:
                            direction = "â†‘" if row['ì„¸ì…˜ë³€í™”'] > 0 else "â†“"
                            insights.append(f"**{idx+1}. {row['ì¸êµ¬í†µê³„']}** {direction} {abs(row['ì„¸ì…˜ë³€í™”']):,.0f}ì„¸ì…˜ ({row['ì„¸ì…˜ì¦ê°ìœ¨']:+.1f}%)")
        except Exception as e:
            pass  # ì¸êµ¬í†µê³„ ë°ì´í„° ì˜¤ë¥˜ ì‹œ ì¡°ìš©íˆ ìŠ¤í‚µ
    
    # 7. ëŒ€ëŸ‰ êµ¬ë§¤ ì˜í–¥
    bulk_change = curr['bulk_revenue'] - prev['bulk_revenue']
    bulk_pct = (bulk_change / prev['bulk_revenue'] * 100) if prev['bulk_revenue'] > 0 else 0
    
    if abs(bulk_pct) > 10 or abs(bulk_change) > 5000000:
        direction = "ì¦ê°€" if bulk_change > 0 else "ê°ì†Œ"
        insights.append(f"\n### ğŸ’¼ ëŒ€ëŸ‰ êµ¬ë§¤ ì˜í–¥")
        insights.append(f"ëŒ€ëŸ‰ êµ¬ë§¤(150ë§Œì›â†‘) ë§¤ì¶œì´ **â‚©{abs(bulk_change):,.0f} ({abs(bulk_pct):.1f}%) {direction}**í–ˆìŠµë‹ˆë‹¤.")
    
    # 8. ì§€ì—­ ë³€í™”
    if 'demo' in insight_data and insight_data['demo'] is not None and not insight_data['demo'].empty:
        top_demo = insight_data['demo'].iloc[0]
        if abs(top_demo['ë§¤ì¶œë³€í™”']) > 1000000:
            direction = "â†‘" if top_demo['ë§¤ì¶œë³€í™”'] > 0 else "â†“"
            insights.append(f"\n### ğŸŒ ì§€ì—­ë³„ ë³€í™”")
            insights.append(f"**{top_demo['ì§€ì—­']}** {direction} â‚©{abs(top_demo['ë§¤ì¶œë³€í™”']):,.0f} ({top_demo['ì¦ê°ìœ¨']:+.1f}%)")
    
    # 9. ì „í™˜ìœ¨ ë³€í™”
    curr_cr = (curr['orders'] / curr['sessions'] * 100) if curr['sessions'] > 0 else 0
    prev_cr = (prev['orders'] / prev['sessions'] * 100) if prev['sessions'] > 0 else 0
    cr_change = curr_cr - prev_cr
    
    if abs(cr_change) > 0.15:
        direction = "ê°œì„ " if cr_change > 0 else "í•˜ë½"
        insights.append(f"\n### ğŸ¯ êµ¬ë§¤ ì „í™˜ìœ¨ {direction}")
        insights.append(f"ì „í™˜ìœ¨ì´ **{abs(cr_change):.2f}%p {direction}**í–ˆìŠµë‹ˆë‹¤ ({prev_cr:.2f}% â†’ {curr_cr:.2f}%).")
    
    return "\n".join(insights) if insights else "ğŸ“Š ì „ê¸° ëŒ€ë¹„ í° ë³€í™”ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

# -------------------------------------------------
# 5. ë©”ì¸ UI
# -------------------------------------------------
st.title("ğŸª‘ SIDIZ AI Intelligence Dashboard")

today = datetime.now().date()

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    
    # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ (3ê°€ì§€ ì˜µì…˜)
    data_source = st.selectbox(
        "ğŸ“Š ë°ì´í„° ì†ŒìŠ¤",
        options=["ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)", "ì „ì²´", "ë§¤ì¥ ì „ìš©"],
        index=0,  # ê¸°ë³¸ê°’: ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)
        help="ì‹œë””ì¦ˆë‹·ì»´: ì˜¨ë¼ì¸ ì „ìš© | ì „ì²´: ëª¨ë“  ë°ì´í„° | ë§¤ì¥ ì „ìš©: ë§¤ì¥ QR ìœ ì…ë§Œ"
    )
    
    # ë‚ ì§œ ì…ë ¥
    curr_date = st.date_input("ë¶„ì„ ê¸°ê°„", [today - timedelta(days=7), today - timedelta(days=1)])
    comp_date = st.date_input("ë¹„êµ ê¸°ê°„", [today - timedelta(days=14), today - timedelta(days=8)])
    
    time_unit = st.selectbox("ì¶”ì´ ë¶„ì„ ë‹¨ìœ„", ["ì¼ë³„", "ì£¼ë³„", "ì›”ë³„"])

if len(curr_date) == 2 and len(comp_date) == 2:
    # ë°ì´í„° ì†ŒìŠ¤ ìƒíƒœ í‘œì‹œ
    if data_source == "ì‹œë””ì¦ˆë‹·ì»´ (ë§¤ì¥ ì œì™¸)":
        st.info("ğŸŒ ì‹œë””ì¦ˆë‹·ì»´ ëª¨ë“œ - ì˜¨ë¼ì¸ ì „ìš© ë°ì´í„°ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
    elif data_source == "ë§¤ì¥ ì „ìš©":
        st.info("ğŸª ë§¤ì¥ ì „ìš© ëª¨ë“œ - ë§¤ì¥ QR ìœ ì… ë°ì´í„°ë§Œ í‘œì‹œë©ë‹ˆë‹¤")
    
    summary_df, ts_df = get_dashboard_data(
        curr_date[0], curr_date[1], 
        comp_date[0], comp_date[1], 
        time_unit, 
        data_source  # exclude_store ëŒ€ì‹  data_source ì „ë‹¬
    )
    
    if summary_df is not None and not summary_df.empty:
        curr = summary_df[summary_df['type'] == 'Current'].iloc[0]
        prev = summary_df[summary_df['type'] == 'Previous'].iloc[0] if 'Previous' in summary_df['type'].values else curr

        def get_delta(c, p):
            if p == 0:
                return "0%"
            return f"{((c - p) / p * 100):+.1f}%"

        # [10ëŒ€ ì§€í‘œ - 2ì¤„ 5ê°œì”©]
        st.subheader("ğŸ¯ í•µì‹¬ ì„±ê³¼ ìš”ì•½")
        
        # ì²« ë²ˆì§¸ ì¤„ (5ê°œ)
        cols = st.columns(5)
        cols[0].metric("í™œì„± ì‚¬ìš©ì", f"{int(curr['users']):,}ëª…", get_delta(curr['users'], prev['users']))
        cols[1].metric("ì‹ ê·œ ì‚¬ìš©ì", f"{int(curr['new_users']):,}ëª…", get_delta(curr['new_users'], prev['new_users']))
        cols[2].metric("ì„¸ì…˜ ìˆ˜", f"{int(curr['sessions']):,}", get_delta(curr['sessions'], prev['sessions']))
        cols[3].metric("íšŒì›ê°€ì…", f"{int(curr['signups']):,}ê±´", get_delta(curr['signups'], prev['signups']))
        
        c_nv = (curr['new_users']/curr['users']*100) if curr['users'] > 0 else 0
        p_nv = (prev['new_users']/prev['users']*100) if prev['users'] > 0 else 0
        cols[4].metric("ì‹ ê·œ ë°©ë¬¸ìœ¨", f"{c_nv:.1f}%", f"{c_nv-p_nv:+.1f}%p")
        
        # ë‘ ë²ˆì§¸ ì¤„ (5ê°œ)
        cols = st.columns(5)
        cols[0].metric("ì£¼ë¬¸ ìˆ˜", f"{int(curr['orders']):,}ê±´", get_delta(curr['orders'], prev['orders']))
        cols[1].metric("ì´ ë§¤ì¶œì•¡", f"â‚©{int(curr['revenue']):,}", get_delta(curr['revenue'], prev['revenue']))
        
        c_cr = (curr['orders']/curr['sessions']*100) if curr['sessions'] > 0 else 0
        p_cr = (prev['orders']/prev['sessions']*100) if prev['sessions'] > 0 else 0
        cols[2].metric("êµ¬ë§¤ ì „í™˜ìœ¨", f"{c_cr:.2f}%", f"{c_cr-p_cr:+.2f}%p")
        
        c_aov = (curr['revenue']/curr['orders']) if curr['orders'] > 0 else 0
        p_aov = (prev['revenue']/prev['orders']) if prev['orders'] > 0 else 0
        cols[3].metric("í‰ê·  ê°ë‹¨ê°€", f"â‚©{int(c_aov):,}", get_delta(c_aov, p_aov))
        
        # EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸ ê°ë‹¨ê°€
        c_filtered_aov = (curr['filtered_revenue']/curr['filtered_orders']) if curr.get('filtered_orders', 0) > 0 else 0
        p_filtered_aov = (prev['filtered_revenue']/prev['filtered_orders']) if prev.get('filtered_orders', 0) > 0 else 0
        
        if c_filtered_aov > 0:
            cols[4].metric("í•„í„°ë§ ê°ë‹¨ê°€", f"â‚©{int(c_filtered_aov):,}", get_delta(c_filtered_aov, p_filtered_aov), 
                          help="EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸")
        else:
            cols[4].metric("í•„í„°ë§ ê°ë‹¨ê°€", "ë°ì´í„° ì—†ìŒ", help="EASY REPAIRë§Œ êµ¬ë§¤í•œ ì£¼ë¬¸ ì œì™¸")

        # [ëŒ€ëŸ‰ êµ¬ë§¤]
        st.markdown("---")
        st.subheader("ğŸ“¦ ëŒ€ëŸ‰ êµ¬ë§¤ ì„¸ê·¸ë¨¼íŠ¸ (150ë§Œ ì›â†‘)")
        b1, b2, b3 = st.columns(3)
        b1.metric("ëŒ€ëŸ‰ ì£¼ë¬¸ ê±´ìˆ˜", f"{int(curr['bulk_orders'])}ê±´", f"{int(curr['bulk_orders'] - prev['bulk_orders']):+}ê±´")
        b2.metric("ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ", f"â‚©{int(curr['bulk_revenue']):,}", get_delta(curr['bulk_revenue'], prev['bulk_revenue']))
        b3.metric("ëŒ€ëŸ‰ ë§¤ì¶œ ë¹„ì¤‘", f"{(curr['bulk_revenue']/curr['revenue']*100 if curr['revenue']>0 else 0):.1f}%")
        
        # ëŒ€ëŸ‰ êµ¬ë§¤ ìƒì„¸ í’ˆëª© (ì ‘ê¸°/í¼ì¹˜ê¸°)
        with st.expander("ğŸ” ëŒ€ëŸ‰ êµ¬ë§¤ í’ˆëª©ë³„ ìƒì„¸ ë³´ê¸°"):
            bulk_detail_query = f"""
            SELECT 
                item.item_name as product_name,
                COUNT(DISTINCT event_timestamp) as order_count,
                SUM(item.quantity) as total_quantity,
                SUM(item.price * item.quantity) as item_revenue
            FROM `sidiz-458301.analytics_487246344.events_*`,
            UNNEST(items) as item
            WHERE _TABLE_SUFFIX BETWEEN '{curr_date[0].strftime('%Y%m%d')}' AND '{curr_date[1].strftime('%Y%m%d')}'
            AND event_name = 'purchase'
            AND ecommerce.purchase_revenue >= 1500000
            GROUP BY item.item_name
            ORDER BY item_revenue DESC
            LIMIT 20
            """
            try:
                bulk_detail = client.query(bulk_detail_query).to_dataframe()
                if not bulk_detail.empty:
                    bulk_detail.columns = ['ì œí’ˆëª…', 'ì£¼ë¬¸ìˆ˜', 'ìˆ˜ëŸ‰', 'ë§¤ì¶œì•¡']
                    bulk_detail['ë§¤ì¶œë¹„ì¤‘'] = (bulk_detail['ë§¤ì¶œì•¡'] / bulk_detail['ë§¤ì¶œì•¡'].sum() * 100).round(1)
                    
                    # í¬ë§·íŒ…
                    display_bulk = bulk_detail.copy()
                    display_bulk.insert(0, 'ìˆœìœ„', range(1, len(display_bulk) + 1))
                    display_bulk['ì£¼ë¬¸ìˆ˜'] = display_bulk['ì£¼ë¬¸ìˆ˜'].apply(lambda x: f"{int(x)}ê±´")
                    display_bulk['ìˆ˜ëŸ‰'] = display_bulk['ìˆ˜ëŸ‰'].apply(lambda x: f"{int(x)}ê°œ")
                    display_bulk['ë§¤ì¶œì•¡'] = display_bulk['ë§¤ì¶œì•¡'].apply(lambda x: f"â‚©{int(x):,}")
                    display_bulk['ë§¤ì¶œë¹„ì¤‘'] = display_bulk['ë§¤ì¶œë¹„ì¤‘'].apply(lambda x: f"{x:.1f}%")
                    
                    st.dataframe(display_bulk, use_container_width=True, height=400)
                else:
                    st.info("ëŒ€ëŸ‰ êµ¬ë§¤ í’ˆëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ëŒ€ëŸ‰ êµ¬ë§¤ ìƒì„¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")


        # [ê°œì„ ëœ ë§¤ì¶œ ì¶”ì´ ì°¨íŠ¸]
        st.markdown("---")
        st.subheader(f"ğŸ“Š {time_unit} ë§¤ì¶œ ì¶”ì´")
        
        if ts_df is not None and not ts_df.empty:
            ts_df['conversion_rate'] = (ts_df['orders'] / ts_df['sessions'] * 100).fillna(0)
            
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            
            # ì„¸ì…˜ ìˆ˜ (ì„  ê·¸ë˜í”„)
            fig.add_trace(
                go.Scatter(
                    x=ts_df['period_label'], 
                    y=ts_df['sessions'], 
                    name="ì„¸ì…˜ ìˆ˜",
                    line=dict(color='#4A90E2', width=3),
                    mode='lines+markers',
                    marker=dict(size=8)
                ),
                secondary_y=False
            )
            
            # ë§¤ì¶œì•¡ (ë§‰ëŒ€ ê·¸ë˜í”„)
            fig.add_trace(
                go.Bar(
                    x=ts_df['period_label'], 
                    y=ts_df['revenue'], 
                    name="ë§¤ì¶œì•¡",
                    marker_color='#50C878',
                    opacity=0.7,
                    text=ts_df['revenue'].apply(lambda x: f'â‚©{x/1000000:.1f}M'),
                    textposition='outside'
                ),
                secondary_y=True
            )
            
            # ì „í™˜ìœ¨ (ì ì„ )
            fig.add_trace(
                go.Scatter(
                    x=ts_df['period_label'], 
                    y=ts_df['conversion_rate'], 
                    name="êµ¬ë§¤ ì „í™˜ìœ¨",
                    line=dict(color='#FF6B6B', width=2, dash='dash'),
                    mode='lines+markers',
                    marker=dict(size=6)
                ),
                secondary_y=False
            )
            
            fig.update_xaxes(title_text="ê¸°ê°„", showgrid=True, gridwidth=1, gridcolor='#E8E8E8')
            fig.update_yaxes(title_text="<b>ì„¸ì…˜ ìˆ˜ / ì „í™˜ìœ¨ (%)</b>", secondary_y=False, showgrid=True, gridwidth=1, gridcolor='#E8E8E8')
            fig.update_yaxes(title_text="<b>ë§¤ì¶œì•¡ (ì›)</b>", secondary_y=True)
            
            fig.update_layout(
                template="plotly_white",
                hovermode="x unified",
                font=dict(size=13, family="Pretendard, -apple-system, sans-serif"),
                legend=dict(
                    orientation="h", 
                    yanchor="bottom", 
                    y=1.02, 
                    xanchor="center", 
                    x=0.5,
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="#CCCCCC",
                    borderwidth=1
                ),
                plot_bgcolor='#FAFAFA',
                height=450
            )
            
            st.plotly_chart(fig, use_container_width=True)

        # [ë°ì´í„° ì¸ì‚¬ì´íŠ¸]
        st.markdown("---")
        st.subheader("ğŸ§  ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸")
        
        with st.spinner("ë¶„ì„ ì¤‘..."):
            insight_data = get_insight_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1], data_source)
            insights = generate_insights(curr, prev, insight_data)
            st.markdown(insights)
            
            # [ê°œì„ ëœ ìƒì„¸ ë°ì´í„° í…Œì´ë¸”]
            with st.expander("ğŸ“‹ ìƒì„¸ ë¶„ì„ ë°ì´í„° ë³´ê¸°"):
                if insight_data:
                    tab1, tab2, tab3, tab4, tab5 = st.tabs([
                        "ì œí’ˆë³„ ë¶„ì„", 
                        "ì±„ë„ë³„ ë¶„ì„",
                        "ì¸êµ¬í†µê³„ë³„ ë¶„ì„",
                        "ì§€ì—­ë³„ ë¶„ì„", 
                        "ë””ë°”ì´ìŠ¤ë³„ ë¶„ì„"
                    ])
                    
                    # ìˆ«ì í¬ë§· í•¨ìˆ˜ (ì•ˆì „í•œ ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
                    def format_currency(val):
                        try:
                            if pd.isna(val) or val == 0:
                                return "â‚©0"
                            return f"â‚©{val:,.0f}"
                        except:
                            return "â‚©0"
                    
                    def format_number(val):
                        try:
                            if pd.isna(val) or val == 0:
                                return "0"
                            return f"{val:,.0f}"
                        except:
                            return "0"
                    
                    def format_percent(val):
                        try:
                            if pd.isna(val):
                                return "-"
                            return f"{val:+.1f}%"
                        except:
                            return "-"
                    
                    with tab1:
                        if 'product' in insight_data and not insight_data['product'].empty:
                            # ê°€ê³µì„ ìœ„í•œ ë³µì‚¬ë³¸ ìƒì„±
                            display_df = insight_data['product'].copy()
                            
                            # ìˆœìœ„ ì¶”ê°€ (1ë¶€í„° ì‹œì‘)
                            display_df.insert(0, 'ìˆœìœ„', range(1, len(display_df) + 1))
                            
                            # í‘œì‹œìš© í¬ë§·íŒ… (ìˆœì„œ ì¤‘ìš”: ê³„ì‚°ì´ ëª¨ë‘ ëë‚œ í›„ ë¬¸ìì—´ë¡œ ë³€í™˜)
                            display_df['í˜„ì¬ë§¤ì¶œ'] = display_df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                            display_df['ì´ì „ë§¤ì¶œ'] = display_df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                            display_df['ë§¤ì¶œë³€í™”'] = display_df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                            display_df['ì¦ê°ìœ¨'] = display_df['ì¦ê°ìœ¨'].apply(lambda x: f"{x:+.1f}%")
                            display_df['ë§¤ì¶œë¹„ì¤‘'] = display_df['ë§¤ì¶œë¹„ì¤‘'].apply(lambda x: f"{x:.1f}%")
                            display_df['í˜„ì¬ì„¸ì…˜'] = display_df['í˜„ì¬ì„¸ì…˜'].apply(format_number)
                            display_df['ì´ì „ì„¸ì…˜'] = display_df['ì´ì „ì„¸ì…˜'].apply(format_number)
                            display_df['ì„¸ì…˜ë³€í™”'] = display_df['ì„¸ì…˜ë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_number(abs(x))}")
                            display_df['í˜„ì¬ìˆ˜ëŸ‰'] = display_df['í˜„ì¬ìˆ˜ëŸ‰'].apply(lambda x: f"{int(x)}ê°œ")
                            display_df['ì´ì „ìˆ˜ëŸ‰'] = display_df['ì´ì „ìˆ˜ëŸ‰'].apply(lambda x: f"{int(x)}ê°œ")
                            display_df['ìˆ˜ëŸ‰ë³€í™”'] = display_df['ìˆ˜ëŸ‰ë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {int(abs(x))}ê°œ")
                            
                            # ì»¬ëŸ¼ ì„ íƒ ë° ìˆœì„œ
                            cols_to_show = ['ìˆœìœ„', 'ì œí’ˆëª…', 'í˜„ì¬ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨', 
                                          'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'í˜„ì¬ìˆ˜ëŸ‰', 'ì´ì „ìˆ˜ëŸ‰', 'ìˆ˜ëŸ‰ë³€í™”']
                            st.dataframe(display_df[cols_to_show], use_container_width=True, height=600)
                        else:
                            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    with tab2:
                        if 'channel_combined' in insight_data and not insight_data['channel_combined'].empty:
                            df = insight_data['channel_combined'].copy()
                            
                            # ë§¤ì¶œ ë¹„ì¤‘ ê³„ì‚°
                            total_revenue = df['í˜„ì¬ë§¤ì¶œ'].sum()
                            if total_revenue > 0:
                                df['ë§¤ì¶œë¹„ì¤‘'] = (df['í˜„ì¬ë§¤ì¶œ'] / total_revenue * 100).round(1)
                            else:
                                df['ë§¤ì¶œë¹„ì¤‘'] = 0
                            
                            # ìˆœìœ„ ì¶”ê°€ (1ë¶€í„° ì‹œì‘)
                            df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
                            
                            # í¬ë§· ì ìš©
                            df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                            df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                            df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                            df['ë§¤ì¶œì¦ê°ìœ¨'] = df['ë§¤ì¶œì¦ê°ìœ¨'].apply(format_percent)
                            df['ë§¤ì¶œë¹„ì¤‘'] = df['ë§¤ì¶œë¹„ì¤‘'].apply(lambda x: f"{x:.1f}%")
                            df['í˜„ì¬ì„¸ì…˜'] = df['í˜„ì¬ì„¸ì…˜'].apply(format_number)
                            df['ì´ì „ì„¸ì…˜'] = df['ì´ì „ì„¸ì…˜'].apply(format_number)
                            df['ì„¸ì…˜ë³€í™”'] = df['ì„¸ì…˜ë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_number(abs(x))}")
                            df['ì„¸ì…˜ì¦ê°ìœ¨'] = df['ì„¸ì…˜ì¦ê°ìœ¨'].apply(format_percent)
                            
                            cols_to_show = ['ìˆœìœ„', 'ì±„ë„', 'í˜„ì¬ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ë§¤ì¶œì¦ê°ìœ¨',
                                          'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì„¸ì…˜ì¦ê°ìœ¨']
                            st.dataframe(df[cols_to_show], use_container_width=True, height=600)
                        else:
                            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    with tab3:
                        if 'demographics_combined' in insight_data and not insight_data['demographics_combined'].empty:
                            df = insight_data['demographics_combined'].copy()
                            
                            # ë§¤ì¶œ ë¹„ì¤‘ ê³„ì‚°
                            total_revenue = df['í˜„ì¬ë§¤ì¶œ'].sum()
                            if total_revenue > 0:
                                df['ë§¤ì¶œë¹„ì¤‘'] = (df['í˜„ì¬ë§¤ì¶œ'] / total_revenue * 100).round(1)
                            else:
                                df['ë§¤ì¶œë¹„ì¤‘'] = 0
                            
                            # ìˆœìœ„ ì¶”ê°€
                            df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
                            
                            # í¬ë§· ì ìš©
                            df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                            df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                            df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                            df['ë§¤ì¶œì¦ê°ìœ¨'] = df['ë§¤ì¶œì¦ê°ìœ¨'].apply(format_percent)
                            df['ë§¤ì¶œë¹„ì¤‘'] = df['ë§¤ì¶œë¹„ì¤‘'].apply(lambda x: f"{x:.1f}%")
                            df['í˜„ì¬ì„¸ì…˜'] = df['í˜„ì¬ì„¸ì…˜'].apply(format_number)
                            df['ì´ì „ì„¸ì…˜'] = df['ì´ì „ì„¸ì…˜'].apply(format_number)
                            df['ì„¸ì…˜ë³€í™”'] = df['ì„¸ì…˜ë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_number(abs(x))}")
                            df['ì„¸ì…˜ì¦ê°ìœ¨'] = df['ì„¸ì…˜ì¦ê°ìœ¨'].apply(format_percent)
                            
                            cols_to_show = ['ìˆœìœ„', 'ì¸êµ¬í†µê³„', 'í˜„ì¬ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ë§¤ì¶œì¦ê°ìœ¨',
                                          'í˜„ì¬ì„¸ì…˜', 'ì´ì „ì„¸ì…˜', 'ì„¸ì…˜ë³€í™”', 'ì„¸ì…˜ì¦ê°ìœ¨']
                            st.dataframe(df[cols_to_show], use_container_width=True, height=600)
                        else:
                            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    with tab4:
                        if 'demo' in insight_data and not insight_data['demo'].empty:
                            df = insight_data['demo'].copy()
                            
                            # ë§¤ì¶œ ë¹„ì¤‘ ê³„ì‚°
                            total_revenue = df['í˜„ì¬ë§¤ì¶œ'].sum()
                            if total_revenue > 0:
                                df['ë§¤ì¶œë¹„ì¤‘'] = (df['í˜„ì¬ë§¤ì¶œ'] / total_revenue * 100).round(1)
                            else:
                                df['ë§¤ì¶œë¹„ì¤‘'] = 0
                            
                            # ìˆœìœ„ ì¶”ê°€
                            df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
                            
                            df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                            df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                            df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                            df['ì¦ê°ìœ¨'] = df['ì¦ê°ìœ¨'].apply(format_percent)
                            df['ë§¤ì¶œë¹„ì¤‘'] = df['ë§¤ì¶œë¹„ì¤‘'].apply(lambda x: f"{x:.1f}%")
                            
                            cols_to_show = ['ìˆœìœ„', 'ì§€ì—­', 'í˜„ì¬ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
                            st.dataframe(df[cols_to_show], use_container_width=True, height=600)
                        else:
                            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    with tab5:
                        if 'device' in insight_data and not insight_data['device'].empty:
                            df = insight_data['device'].copy()
                            
                            # ë§¤ì¶œ ë¹„ì¤‘ ê³„ì‚°
                            total_revenue = df['í˜„ì¬ë§¤ì¶œ'].sum()
                            if total_revenue > 0:
                                df['ë§¤ì¶œë¹„ì¤‘'] = (df['í˜„ì¬ë§¤ì¶œ'] / total_revenue * 100).round(1)
                            else:
                                df['ë§¤ì¶œë¹„ì¤‘'] = 0
                            
                            # ìˆœìœ„ ì¶”ê°€
                            df.insert(0, 'ìˆœìœ„', range(1, len(df) + 1))
                            
                            df['í˜„ì¬ë§¤ì¶œ'] = df['í˜„ì¬ë§¤ì¶œ'].apply(format_currency)
                            df['ì´ì „ë§¤ì¶œ'] = df['ì´ì „ë§¤ì¶œ'].apply(format_currency)
                            df['ë§¤ì¶œë³€í™”'] = df['ë§¤ì¶œë³€í™”'].apply(lambda x: f"{'â†‘' if x > 0 else 'â†“'} {format_currency(abs(x))}")
                            df['ì¦ê°ìœ¨'] = df['ì¦ê°ìœ¨'].apply(format_percent)
                            df['ë§¤ì¶œë¹„ì¤‘'] = df['ë§¤ì¶œë¹„ì¤‘'].apply(lambda x: f"{x:.1f}%")
                            
                            cols_to_show = ['ìˆœìœ„', 'ë””ë°”ì´ìŠ¤', 'í˜„ì¬ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘', 'ì´ì „ë§¤ì¶œ', 'ë§¤ì¶œë³€í™”', 'ì¦ê°ìœ¨']
                            st.dataframe(df[cols_to_show], use_container_width=True, height=600)
                        else:
                            st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
