import streamlit as st
import google.generativeai as genai
from google.cloud import bigquery
import pandas as pd
import json
import plotly.express as px

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="SIDIZ AI Intelligence", page_icon="ğŸª‘", layout="wide")
st.markdown("""
    <style>
    .main { background-color: #f5f5f5; }
    .stChatMessage { border-radius: 15px; }
    </style>
    """, unsafe_allow_html=True)

# 2. ë³´ì•ˆ ì„¤ì • (Secrets)
info = json.loads(st.secrets["gcp_service_account"]["json_key"])
client = bigquery.Client.from_service_account_info(info)
genai.configure(api_key=st.secrets["gemini"]["api_key"])

# 3. ì œë¯¸ë‚˜ì´ í˜ë¥´ì†Œë‚˜ ë° ë°ì´í„° ì‚¬ì „ ì •ì˜ (í•µì‹¬!)
SYSTEM_PROMPT = f"""
ë‹¹ì‹ ì€ ì‹œë””ì¦ˆ(SIDIZ)ì˜ ì‹œë‹ˆì–´ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
ë‹¹ì‹ ì€ ë£¨ì»¤ìŠ¤íŠœë””ì˜¤ ë³´ê³ ì„œì— ì—†ëŠ” ê¹Šì´ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

[ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„° ë²”ìœ„]
- í…Œì´ë¸”: `{info['project_id']}.analytics_324424314.events_*`
- ì§€í‘œ: ì„¸ì…˜, ì‚¬ìš©ì, êµ¬ë§¤, íšŒì›ê°€ì…, ì •í’ˆë“±ë¡, ì œí’ˆ í´ë¦­ ë“±
- íŠ¹ìˆ˜ ë¶„ì„: 
    1. ë©€í‹° í„°ì¹˜ ê¸°ì—¬ ë¶„ì„ (ìœ ì… ê²½ë¡œ íˆìŠ¤í† ë¦¬ ì¶”ì )
    2. ì œí’ˆ ê°„ êµì°¨ êµ¬ë§¤ ë¶„ì„ (T50 êµ¬ë§¤ìê°€ ë®¤ë¸Œë„ ë³´ëŠ”ì§€?)
    3. ì´íƒˆ ë¶„ì„ (ì¥ë°”êµ¬ë‹ˆ ë‹´ê¸° í›„ ì™œ ê²°ì œë¥¼ ì•ˆ í•˜ëŠ”ì§€?)

[SQL ì‘ì„± ê·œì¹™]
- GA4 ë¹…ì¿¼ë¦¬ì˜ UNNEST ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”.
- ë‚ ì§œ í•„í„°ëŠ” í•­ìƒ _TABLE_SUFFIXë¥¼ í™œìš©í•´ íš¨ìœ¨ì ìœ¼ë¡œ ì§­ë‹ˆë‹¤.
- ê¸°ì—¬ ë¶„ì„ ì‹œ user_pseudo_idì™€ event_timestampë¥¼ í™œìš©í•´ ê²½ë¡œë¥¼ ì¬êµ¬ì„±í•˜ì„¸ìš”.
"""

model = genai.GenerativeModel('gemini-1.5-pro', system_instruction=SYSTEM_PROMPT)

st.title("ğŸª‘ SIDIZ Data Intelligence Portal")
st.sidebar.header("ğŸ“Œ ë¶„ì„ ì¶”ì²œ ì§ˆë¬¸")
if st.sidebar.button("ìœ íŠœë¸Œ ìœ ì…ìì˜ ê²°ì œ ê¸°ì—¬ë„ ë¶„ì„"):
    st.session_state.prompt = "ìœ íŠœë¸Œ(ig/social ë“±)ë¡œ ì²˜ìŒ ë“¤ì–´ì˜¨ ì‚¬ìš©ìë“¤ì´ ê²°ì œê¹Œì§€ ê°€ëŠ” ê³¼ì •ì—ì„œ ê±°ì¹˜ëŠ” ê²½ë¡œë“¤ì„ ë¶„ì„í•´ì¤˜."

# 4. ì±„íŒ… ë£¨í”„
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë°ì´í„°ì—ê²Œ ë§ì„ ê±¸ì–´ë³´ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ë¹…ì¿¼ë¦¬ì—ì„œ ê³ ê° ì—¬ì •ì„ ì¶”ì  ì¤‘..."):
            # ì œë¯¸ë‚˜ì´ê°€ SQL ìƒì„± ë° ë¶„ì„
            response = model.generate_content(prompt)
            st.markdown(response.text)
            
            # (ì—¬ê¸°ì— ì‹¤ì œ SQL ì‹¤í–‰ ë° ì‹œê°í™” ë¡œì§ì„ ì¶”ê°€í•˜ì—¬ ì°¨íŠ¸ë¥¼ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
            # ì˜ˆì‹œë¡œ ë°ì´í„° í”„ë ˆì„ êµ¬ì¡°ë§Œ ë³´ì—¬ì¤Œ
            # st.plotly_chart(fig)

    st.session_state.messages.append({"role": "assistant", "content": response.text})
