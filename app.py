import streamlit as st
from google.cloud import bigquery
import pandas as pd
import json
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="SIDIZ Intelligence Dashboard", layout="wide")

@st.cache_resource
def get_bq_client():
    try:
        info = json.loads(st.secrets["gcp_service_account"]["json_key"])
        return bigquery.Client.from_service_account_info(info, location="asia-northeast3")
    except Exception as e:
        st.error(f"âŒ BigQuery ì¸ì¦ ì‹¤íŒ¨: {e}")
        return None

client = get_bq_client()

# -------------------------------------------------
# 2. í•µì‹¬ ì§€í‘œ ë°ì´í„° ì¶”ì¶œ
# -------------------------------------------------
def get_dashboard_data(start_c, end_c, start_p, end_p):
    if client is None: 
        return None, None, None
    
    s_c, e_c = start_c.strftime('%Y%m%d'), end_c.strftime('%Y%m%d')
    s_p, e_p = start_p.strftime('%Y%m%d'), end_p.strftime('%Y%m%d')

    # í•µì‹¬ ì§€í‘œ ì¿¼ë¦¬ (íšŒì›ê°€ì… í¬í•¨)
    query = f"""
    WITH base AS (
        SELECT 
            PARSE_DATE('%Y%m%d', event_date) as date,
            user_pseudo_id, 
            event_name, 
            ecommerce.purchase_revenue,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) as sid,
            (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_number' LIMIT 1) as s_num
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{min(s_c, s_p)}' AND '{max(e_c, e_p)}'
    )
    SELECT 
        CASE WHEN date BETWEEN PARSE_DATE('%Y%m%d', '{s_c}') AND PARSE_DATE('%Y%m%d', '{e_c}') THEN 'Current' ELSE 'Previous' END as type,
        COUNT(DISTINCT user_pseudo_id) as users,
        COUNT(DISTINCT CASE WHEN s_num = 1 THEN user_pseudo_id END) as new_users,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST(sid AS STRING))) as sessions,
        COUNTIF(event_name = 'sign_up') as signups,
        COUNTIF(event_name = 'purchase') as orders,
        SUM(IFNULL(purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase' AND purchase_revenue >= 1500000) as bulk_orders,
        SUM(CASE WHEN event_name = 'purchase' AND purchase_revenue >= 1500000 THEN purchase_revenue ELSE 0 END) as bulk_revenue
    FROM base 
    GROUP BY 1 
    HAVING type IS NOT NULL
    """

    # ì‹œê³„ì—´ ë°ì´í„° (ì¼ë³„)
    ts_query = f"""
    SELECT 
        event_date,
        COUNT(DISTINCT CONCAT(user_pseudo_id, CAST((SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id' LIMIT 1) AS STRING))) as sessions,
        SUM(IFNULL(ecommerce.purchase_revenue, 0)) as revenue,
        COUNTIF(event_name = 'purchase') as orders
    FROM `sidiz-458301.analytics_487246344.events_*`
    WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
    GROUP BY 1 
    ORDER BY 1
    """

    try:
        summary_df = client.query(query).to_dataframe()
        ts_df = client.query(ts_query).to_dataframe()
        return summary_df, ts_df
    except Exception as e:
        st.error(f"âš ï¸ ì¿¼ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None

# -------------------------------------------------
# 3. ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¿¼ë¦¬
# -------------------------------------------------
def get_insight_data(start_c, end_c, start_p, end_p):
    """ë§¤ì¶œ ë³€ë™ ì›ì¸ ë¶„ì„ì„ ìœ„í•œ ìƒì„¸ ë°ì´í„°"""
    if client is None:
        return None
    
    s_c, e_c = start_c.strftime('%Y%m%d'), end_c.strftime('%Y%m%d')
    s_p, e_p = start_p.strftime('%Y%m%d'), end_p.strftime('%Y%m%d')
    
    # 1. ì œí’ˆë³„ ë§¤ì¶œ ë³€í™”
    product_query = f"""
    WITH current_products AS (
        SELECT 
            item.item_name as product,
            SUM(item.quantity) as qty,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`,
        UNNEST(items) as item
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_products AS (
        SELECT 
            item.item_name as product,
            SUM(item.quantity) as qty,
            SUM(ecommerce.purchase_revenue) as revenue
        FROM `sidiz-458301.analytics_487246344.events_*`,
        UNNEST(items) as item
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.product, p.product) as product,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change,
        IFNULL(c.qty, 0) as current_qty,
        IFNULL(p.qty, 0) as previous_qty
    FROM current_products c
    FULL OUTER JOIN previous_products p ON c.product = p.product
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    LIMIT 10
    """
    
    # 2. ì±„ë„ë³„ ë§¤ì¶œ ë³€í™”
    channel_query = f"""
    WITH current_channels AS (
        SELECT 
            CONCAT(traffic_source.source, ' / ', traffic_source.medium) as channel,
            SUM(ecommerce.purchase_revenue) as revenue,
            COUNT(DISTINCT user_pseudo_id) as users
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_channels AS (
        SELECT 
            CONCAT(traffic_source.source, ' / ', traffic_source.medium) as channel,
            SUM(ecommerce.purchase_revenue) as revenue,
            COUNT(DISTINCT user_pseudo_id) as users
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.channel, p.channel) as channel,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change,
        IFNULL(c.users, 0) as current_users,
        IFNULL(p.users, 0) as previous_users
    FROM current_channels c
    FULL OUTER JOIN previous_channels p ON c.channel = p.channel
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    LIMIT 10
    """
    
    # 3. ì¸êµ¬í†µê³„ ë³€í™” (êµ­ê°€, ë„ì‹œ)
    demo_query = f"""
    WITH current_demo AS (
        SELECT 
            geo.country as country,
            geo.city as city,
            SUM(ecommerce.purchase_revenue) as revenue,
            COUNT(DISTINCT user_pseudo_id) as users
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1, 2
    ),
    previous_demo AS (
        SELECT 
            geo.country as country,
            geo.city as city,
            SUM(ecommerce.purchase_revenue) as revenue,
            COUNT(DISTINCT user_pseudo_id) as users
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1, 2
    )
    SELECT 
        COALESCE(c.country, p.country) as country,
        COALESCE(c.city, p.city) as city,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change
    FROM current_demo c
    FULL OUTER JOIN previous_demo p ON c.country = p.country AND c.city = p.city
    WHERE IFNULL(c.revenue, 0) + IFNULL(p.revenue, 0) > 0
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    LIMIT 10
    """
    
    # 4. ë””ë°”ì´ìŠ¤ë³„ ë³€í™”
    device_query = f"""
    WITH current_device AS (
        SELECT 
            device.category as device,
            SUM(ecommerce.purchase_revenue) as revenue,
            COUNT(DISTINCT user_pseudo_id) as users
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_c}' AND '{e_c}'
        AND event_name = 'purchase'
        GROUP BY 1
    ),
    previous_device AS (
        SELECT 
            device.category as device,
            SUM(ecommerce.purchase_revenue) as revenue,
            COUNT(DISTINCT user_pseudo_id) as users
        FROM `sidiz-458301.analytics_487246344.events_*`
        WHERE _TABLE_SUFFIX BETWEEN '{s_p}' AND '{e_p}'
        AND event_name = 'purchase'
        GROUP BY 1
    )
    SELECT 
        COALESCE(c.device, p.device) as device,
        IFNULL(c.revenue, 0) as current_revenue,
        IFNULL(p.revenue, 0) as previous_revenue,
        IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0) as revenue_change
    FROM current_device c
    FULL OUTER JOIN previous_device p ON c.device = p.device
    ORDER BY ABS(IFNULL(c.revenue, 0) - IFNULL(p.revenue, 0)) DESC
    """
    
    try:
        product_df = client.query(product_query).to_dataframe()
        channel_df = client.query(channel_query).to_dataframe()
        demo_df = client.query(demo_query).to_dataframe()
        device_df = client.query(device_query).to_dataframe()
        
        return {
            'product': product_df,
            'channel': channel_df,
            'demo': demo_df,
            'device': device_df
        }
    except Exception as e:
        st.error(f"âš ï¸ ì¸ì‚¬ì´íŠ¸ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

# -------------------------------------------------
# 4. ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±
# -------------------------------------------------
def generate_data_insights(curr, prev, insight_data):
    """GA4 ë°ì´í„° ê¸°ë°˜ ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    
    insights = []
    
    # 1. ì „ì²´ ë§¤ì¶œ ë³€ë™ ë¶„ì„
    revenue_change = curr['revenue'] - prev['revenue']
    revenue_change_pct = (revenue_change / prev['revenue'] * 100) if prev['revenue'] > 0 else 0
    
    if abs(revenue_change_pct) > 5:
        direction = "ì¦ê°€" if revenue_change > 0 else "ê°ì†Œ"
        insights.append(f"### ğŸ“Š ì „ì²´ ë§¤ì¶œ {direction}")
        insights.append(f"ë§¤ì¶œì´ ì „ê¸° ëŒ€ë¹„ **{abs(revenue_change_pct):.1f}% {direction}**í–ˆìŠµë‹ˆë‹¤ (â‚©{abs(revenue_change):,.0f}).")
    
    # 2. ì œí’ˆ ì˜í–¥ ë¶„ì„
    if insight_data and 'product' in insight_data:
        top_product = insight_data['product'].iloc[0]
        if abs(top_product['revenue_change']) > 1000000:
            direction = "ì¦ê°€" if top_product['revenue_change'] > 0 else "ê°ì†Œ"
            insights.append(f"\n### ğŸ† ì£¼ìš” ì œí’ˆ ì˜í–¥")
            insights.append(f"**'{top_product['product']}'** ì œí’ˆì˜ ë§¤ì¶œì´ â‚©{abs(top_product['revenue_change']):,.0f} {direction}í•˜ì—¬ ì „ì²´ ë§¤ì¶œì— í° ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.")
            insights.append(f"- í˜„ì¬ ê¸°ê°„: â‚©{top_product['current_revenue']:,.0f} ({top_product['current_qty']:.0f}ê°œ)")
            insights.append(f"- ì´ì „ ê¸°ê°„: â‚©{top_product['previous_revenue']:,.0f} ({top_product['previous_qty']:.0f}ê°œ)")
    
    # 3. ì±„ë„ ì˜í–¥ ë¶„ì„
    if insight_data and 'channel' in insight_data:
        top_channel = insight_data['channel'].iloc[0]
        if abs(top_channel['revenue_change']) > 500000:
            direction = "ì¦ê°€" if top_channel['revenue_change'] > 0 else "ê°ì†Œ"
            insights.append(f"\n### ğŸ¯ ì£¼ìš” ì±„ë„ ì˜í–¥")
            insights.append(f"**{top_channel['channel']}** ì±„ë„ì˜ ë§¤ì¶œì´ â‚©{abs(top_channel['revenue_change']):,.0f} {direction}í–ˆìŠµë‹ˆë‹¤.")
            insights.append(f"- í˜„ì¬ ê¸°ê°„ êµ¬ë§¤ì: {top_channel['current_users']:.0f}ëª…")
            insights.append(f"- ì´ì „ ê¸°ê°„ êµ¬ë§¤ì: {top_channel['previous_users']:.0f}ëª…")
    
    # 4. ëŒ€ëŸ‰ êµ¬ë§¤ ì˜í–¥ ë¶„ì„
    bulk_change = curr['bulk_orders'] - prev['bulk_orders']
    bulk_rev_change = curr['bulk_revenue'] - prev['bulk_revenue']
    
    if abs(bulk_change) >= 2 or abs(bulk_rev_change) > 5000000:
        direction = "ì¦ê°€" if bulk_change > 0 else "ê°ì†Œ"
        insights.append(f"\n### ğŸ’¼ ëŒ€ëŸ‰ êµ¬ë§¤ (150ë§Œì› ì´ìƒ) ì˜í–¥")
        insights.append(f"ëŒ€ëŸ‰ êµ¬ë§¤ ì£¼ë¬¸ì´ **{abs(bulk_change):.0f}ê±´ {direction}**í–ˆìŠµë‹ˆë‹¤ (ë§¤ì¶œ â‚©{abs(bulk_rev_change):,.0f} {direction}).")
        
        bulk_share_curr = (curr['bulk_revenue'] / curr['revenue'] * 100) if curr['revenue'] > 0 else 0
        bulk_share_prev = (prev['bulk_revenue'] / prev['revenue'] * 100) if prev['revenue'] > 0 else 0
        insights.append(f"- ì „ì²´ ë§¤ì¶œ ëŒ€ë¹„ ë¹„ì¤‘: {bulk_share_curr:.1f}% (ì „ê¸°: {bulk_share_prev:.1f}%)")
    
    # 5. ì¸êµ¬í†µê³„ ë³€í™” ë¶„ì„
    if insight_data and 'demo' in insight_data and not insight_data['demo'].empty:
        top_demo = insight_data['demo'].iloc[0]
        if abs(top_demo['revenue_change']) > 500000:
            direction = "ì¦ê°€" if top_demo['revenue_change'] > 0 else "ê°ì†Œ"
            insights.append(f"\n### ğŸŒ ì§€ì—­ë³„ ë³€í™”")
            location = f"{top_demo['country']} / {top_demo['city']}" if pd.notna(top_demo['city']) else top_demo['country']
            insights.append(f"**{location}** ì§€ì—­ì˜ ë§¤ì¶œì´ â‚©{abs(top_demo['revenue_change']):,.0f} {direction}í–ˆìŠµë‹ˆë‹¤.")
    
    # 6. ë””ë°”ì´ìŠ¤ ë³€í™” ë¶„ì„
    if insight_data and 'device' in insight_data:
        for _, row in insight_data['device'].iterrows():
            if abs(row['revenue_change']) > 1000000:
                direction = "ì¦ê°€" if row['revenue_change'] > 0 else "ê°ì†Œ"
                insights.append(f"\n### ğŸ“± ë””ë°”ì´ìŠ¤ ë³€í™”")
                insights.append(f"**{row['device']}** ë””ë°”ì´ìŠ¤ì˜ ë§¤ì¶œì´ â‚©{abs(row['revenue_change']):,.0f} {direction}í–ˆìŠµë‹ˆë‹¤.")
                break
    
    # 7. ì „í™˜ìœ¨ ë¶„ì„
    curr_cr = (curr['orders'] / curr['sessions'] * 100) if curr['sessions'] > 0 else 0
    prev_cr = (prev['orders'] / prev['sessions'] * 100) if prev['sessions'] > 0 else 0
    cr_change = curr_cr - prev_cr
    
    if abs(cr_change) > 0.2:
        direction = "ê°œì„ " if cr_change > 0 else "í•˜ë½"
        insights.append(f"\n### ğŸ¯ ì „í™˜ìœ¨ {direction}")
        insights.append(f"êµ¬ë§¤ ì „í™˜ìœ¨ì´ **{abs(cr_change):.2f}%p {direction}**í–ˆìŠµë‹ˆë‹¤ ({prev_cr:.2f}% â†’ {curr_cr:.2f}%).")
    
    # 8. ì‹ ê·œ ì‚¬ìš©ì ì˜í–¥
    new_user_change_pct = ((curr['new_users'] - prev['new_users']) / prev['new_users'] * 100) if prev['new_users'] > 0 else 0
    
    if abs(new_user_change_pct) > 10:
        direction = "ì¦ê°€" if new_user_change_pct > 0 else "ê°ì†Œ"
        insights.append(f"\n### ğŸ‘¥ ì‹ ê·œ ì‚¬ìš©ì {direction}")
        insights.append(f"ì‹ ê·œ ì‚¬ìš©ìê°€ **{abs(new_user_change_pct):.1f}% {direction}**í–ˆìŠµë‹ˆë‹¤ ({prev['new_users']:.0f}ëª… â†’ {curr['new_users']:.0f}ëª…).")
    
    if not insights:
        return "ë°ì´í„° ë¶„ì„ ê²°ê³¼, ì „ê¸° ëŒ€ë¹„ í° ë³€í™”ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    return "\n".join(insights)

# -------------------------------------------------
# 5. ë©”ì¸ UI
# -------------------------------------------------
st.title("ğŸª‘ SIDIZ AI Intelligence Dashboard")

today = datetime.now()
with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    curr_date = st.date_input("ë¶„ì„ ê¸°ê°„", [today - timedelta(days=7), today - timedelta(days=1)])
    comp_date = st.date_input("ë¹„êµ ê¸°ê°„", [today - timedelta(days=14), today - timedelta(days=8)])

if len(curr_date) == 2 and len(comp_date) == 2:
    summary_df, ts_df = get_dashboard_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1])
    
    if summary_df is not None and not summary_df.empty:
        curr = summary_df[summary_df['type'] == 'Current'].iloc[0]
        prev = summary_df[summary_df['type'] == 'Previous'].iloc[0] if 'Previous' in summary_df['type'].values else curr

        # ì¦ê°ìœ¨ ê³„ì‚° í•¨ìˆ˜
        def get_delta(c, p):
            if p == 0: return "0%"
            return f"{((c - p) / p * 100):+.1f}%"

        # [9ëŒ€ ì§€í‘œ ì¶œë ¥ - íšŒì›ê°€ì… ì¶”ê°€]
        st.subheader("ğŸ¯ í•µì‹¬ ì„±ê³¼ ìš”ì•½")
        c1, c2, c3, c4 = st.columns(4)
        
        c1.metric("í™œì„± ì‚¬ìš©ì", f"{int(curr['users']):,}", get_delta(curr['users'], prev['users']))
        c1.metric("ì„¸ì…˜ ìˆ˜", f"{int(curr['sessions']):,}", get_delta(curr['sessions'], prev['sessions']))
        
        c2.metric("ì‹ ê·œ ì‚¬ìš©ì", f"{int(curr['new_users']):,}", get_delta(curr['new_users'], prev['new_users']))
        c2.metric("íšŒì›ê°€ì…", f"{int(curr['signups']):,}", get_delta(curr['signups'], prev['signups']))
        
        c_nv = (curr['new_users']/curr['users']*100) if curr['users'] > 0 else 0
        p_nv = (prev['new_users']/prev['users']*100) if prev['users'] > 0 else 0
        c3.metric("ì‹ ê·œ ë°©ë¬¸ìœ¨", f"{c_nv:.1f}%", f"{c_nv-p_nv:+.1f}%p")
        c3.metric("êµ¬ë§¤ì „í™˜ìœ¨", f"{(curr['orders']/curr['sessions']*100):.2f}%", f"{(curr['orders']/curr['sessions']*100 - prev['orders']/prev['sessions']*100):+.2f}%p")
        
        c4.metric("ì£¼ë¬¸ ìˆ˜", f"{int(curr['orders']):,}", get_delta(curr['orders'], prev['orders']))
        c4.metric("ì´ ë§¤ì¶œì•¡", f"â‚©{int(curr['revenue']):,}", get_delta(curr['revenue'], prev['revenue']))
        
        c_aov = (curr['revenue']/curr['orders']) if curr['orders'] > 0 else 0
        p_aov = (prev['revenue']/prev['orders']) if prev['orders'] > 0 else 0
        
        st.markdown("---")
        st.metric("í‰ê·  ê°ë‹¨ê°€(AOV)", f"â‚©{int(c_aov):,}", get_delta(c_aov, p_aov))

        # [ëŒ€ëŸ‰ êµ¬ë§¤ ì„¸ê·¸ë¨¼íŠ¸]
        st.markdown("---")
        st.subheader("ğŸ“¦ ëŒ€ëŸ‰ êµ¬ë§¤ ì„¸ê·¸ë¨¼íŠ¸ (150ë§Œ ì›â†‘)")
        b1, b2, b3 = st.columns(3)
        b1.metric("ëŒ€ëŸ‰ ì£¼ë¬¸ ê±´ìˆ˜", f"{int(curr['bulk_orders'])}ê±´", f"{int(curr['bulk_orders'] - prev['bulk_orders']):+}ê±´")
        b2.metric("ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ", f"â‚©{int(curr['bulk_revenue']):,}", get_delta(curr['bulk_revenue'], prev['bulk_revenue']))
        b3.metric("ëŒ€ëŸ‰ êµ¬ë§¤ ë§¤ì¶œ ë¹„ì¤‘", f"{(curr['bulk_revenue']/curr['revenue']*100 if curr['revenue']>0 else 0):.1f}%")

        # [ë§¤ì¶œ ì¶”ì´ ì°¨íŠ¸ - 3ì¶•]
        st.markdown("---")
        st.subheader("ğŸ“Š ì¼ë³„ ë§¤ì¶œ ì¶”ì´")
        
        if ts_df is not None and not ts_df.empty:
            # ì „í™˜ìœ¨ ê³„ì‚°
            ts_df['conversion_rate'] = (ts_df['orders'] / ts_df['sessions'] * 100).fillna(0)
            
            # 3ì¶• ì°¨íŠ¸ ìƒì„±
            fig = make_subplots(specs=[[{"secondary_y": True}]])
            
            # ì„¸ì…˜ ìˆ˜ (ì™¼ìª½ ì¶•)
            fig.add_trace(
                go.Scatter(x=ts_df['event_date'], y=ts_df['sessions'], name="ì„¸ì…˜ ìˆ˜", 
                          line=dict(color='#1f77b4', width=2)),
                secondary_y=False
            )
            
            # ë§¤ì¶œì•¡ (ì˜¤ë¥¸ìª½ ì¶•)
            fig.add_trace(
                go.Bar(x=ts_df['event_date'], y=ts_df['revenue'], name="ë§¤ì¶œì•¡",
                      marker_color='#2ca02c', opacity=0.6),
                secondary_y=True
            )
            
            # êµ¬ë§¤ ì „í™˜ìœ¨ (ì™¼ìª½ ì¶•, ì‘ì€ ê°’)
            fig.add_trace(
                go.Scatter(x=ts_df['event_date'], y=ts_df['conversion_rate'], name="êµ¬ë§¤ ì „í™˜ìœ¨ (%)",
                          line=dict(color='#ff7f0e', width=2, dash='dash')),
                secondary_y=False
            )
            
            fig.update_xaxes(title_text="ë‚ ì§œ")
            fig.update_yaxes(title_text="ì„¸ì…˜ ìˆ˜ / ì „í™˜ìœ¨ (%)", secondary_y=False)
            fig.update_yaxes(title_text="ë§¤ì¶œì•¡ (ì›)", secondary_y=True)
            
            fig.update_layout(
                template="plotly_white",
                hovermode="x unified",
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            
            st.plotly_chart(fig, use_container_width=True)

        # [ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸]
        st.markdown("---")
        st.subheader("ğŸ§  GA4/BigQuery ë°ì´í„° ì¸ì‚¬ì´íŠ¸")
        
        with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
            insight_data = get_insight_data(curr_date[0], curr_date[1], comp_date[0], comp_date[1])
            insights = generate_data_insights(curr, prev, insight_data)
            st.markdown(insights)
            
            # ìƒì„¸ ë°ì´í„° í…Œì´ë¸” (ì˜µì…˜)
            with st.expander("ğŸ“‹ ìƒì„¸ ë¶„ì„ ë°ì´í„° ë³´ê¸°"):
                if insight_data:
                    tab1, tab2, tab3, tab4 = st.tabs(["ì œí’ˆë³„", "ì±„ë„ë³„", "ì§€ì—­ë³„", "ë””ë°”ì´ìŠ¤ë³„"])
                    
                    with tab1:
                        st.dataframe(insight_data['product'].head(10), use_container_width=True)
                    with tab2:
                        st.dataframe(insight_data['channel'].head(10), use_container_width=True)
                    with tab3:
                        st.dataframe(insight_data['demo'].head(10), use_container_width=True)
                    with tab4:
                        st.dataframe(insight_data['device'], use_container_width=True)

else:
    st.info("ğŸ’¡ ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
